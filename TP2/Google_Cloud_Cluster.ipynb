{"cells": [{"cell_type": "markdown", "metadata": {"id": "4mh2MiuVMazk"}, "source": "# TP2 - Market Basket Analysis \nINF8111 - Fouille de donn\u00e9es, Automne 2022\n### Membres de l'\u00e9quipe / Team Components\n    - Andi Podgorica (1955913)\n    - Benjamin Boucher-Charest (1950849)\n"}, {"cell_type": "markdown", "metadata": {"id": "bh1o2bpwPQJG"}, "source": "## Date et directives de remise / Delivery date and instructions\nVous remettrez ce fichier nomm\u00e9 TP2\\_NomDuMembre1\\_NomDuMembre2\\_NomDuMembre3.ipynb dans la bo\u00eete de remise sur moodle. \n\n**Date limite: Novembre 6 at 23:55**.\n___\nYou should upload the file named TP2\\_nameOfMember1\\_nameOfMember2\\_nameOfMember3.ipynb on moodle.\n\nEverything must be uploaded before **November 6th at 23:55**."}, {"cell_type": "markdown", "metadata": {"id": "VmJEz5JEMazl"}, "source": "## 1. Introduction: Market Basket Analysis\n\nLe *Market Basket Analysis* (MBA) est une technique d'analyse de la fouille de donn\u00e9es qui permet de d\u00e9couvrir les associations entre les produits ou leur regroupement. En explorant des motifs int\u00e9ressants \u00e0 partir d'une vaste collection de donn\u00e9es, le MBA vise \u00e0 comprendre / r\u00e9v\u00e9ler les comportements d'achat des clients en se basant sur la th\u00e9orie selon laquelle si vous avez achet\u00e9 un certain ensemble de produits, vous \u00eates plus (ou moins) susceptible d'acheter un autre groupe de produits. En d'autres termes, le MBA permet aux d\u00e9taillants d'identifier la relation entre les articles que les clients ach\u00e8tent, r\u00e9v\u00e9lant des tendances d'articles souvent achet\u00e9s ensemble.\n\nUne approche largement utilis\u00e9e pour explorer ces motifs consiste \u00e0 construire *** des r\u00e8gles d'association *** telles que\n- **si** achet\u00e9 *ITEM_1* **alors** ach\u00e8tera *ITEM_2* avec **confiance** *X*.\n\nCes associations n'ont pas \u00e0 \u00eatre des r\u00e8gles individuelles. Ils peuvent impliquer de nombreux \u00e9l\u00e9ments. Par exemple, une personne dans un supermarch\u00e9 peut ajouter des \u0153ufs dans son panier, puis le MBA peut sugg\u00e9rer qu'elle ach\u00e8tera \u00e9galement du pain et/ou de la farine:\n\n+ **si**  achet\u00e9 *OEUFS* **alors** ach\u00e8tera [*PAIN* avec confiance *0,2*; *FARINE* avec confiance 0,05].\n\nCependant, si la personne d\u00e9cide maintenant d'ajouter de la farine \u00e0 son panier, la nouvelle r\u00e8gle d'association pourrait \u00eatre comme ci-dessous, sugg\u00e9rant des ingr\u00e9dients pour faire un g\u00e2teau.\n\n+ **si** achet\u00e9 [*OEUFS, FARINE*] **alors** ach\u00e8tera [*SUCRE* avec confiance 0,45; LEVURE avec confiance 0,12; *PAIN* avec confiance *0,03*].\n\nIl existe de nombreux sc\u00e9narios r\u00e9els o\u00f9 le MBA joue un r\u00f4le central dans l'analyse des donn\u00e9es, comme les transactions de supermarch\u00e9, les commandes en ligne ou l'historique des cartes de cr\u00e9dit. Les sp\u00e9cialistes du marketing peuvent utiliser ces r\u00e8gles d'association pour organiser les produits corr\u00e9l\u00e9s plus pr\u00e8s les uns des autres sur les \u00e9tag\u00e8res des magasins ou faire des suggestions en ligne afin que les clients ach\u00e8tent plus d'articles. Un MBA peut g\u00e9n\u00e9ralement aider les d\u00e9taillants \u00e0 r\u00e9pondre aux questions les suivantes:\n\n- Quels articles sont souvent achet\u00e9s ensemble ?\n- \u00c9tant donn\u00e9 un panier, quels articles sugg\u00e9rer ?\n- Comment placer les articles ensemble sur les \u00e9tag\u00e8res ?\n___\nMarket Basket Analysis (MBA) is a data mining analytics technique to uncover associations between products or product grouping. By exploring interesting patterns from an extensive collection of data, MBA aims to understand/reveal customer purchase behaviors based upon the theory that if you purchased a certain set of products, then you are more (or less) likely to buy another group of products. In other words, MBA allows retailers to identify the relationship between the items that customers buy, revealing patterns of items often purchased together.\n\nA widely used approach to explore these patterns is by constructing ***association rules*** such as\n- **if** bought *ITEM_1* **then** will buy *ITEM_2* with **confidence** *X*.\n\nThese associations do not have to be 1-to-1 rules. They can involve many items. For example, a person in a supermarket may add eggs to his/her cart, then an MBA application may suggest that the person will also buy some bread and/or flour: \n\n+ **if** bought *EGGS* **then** will buy [*BREAD* with confidence *0.2*; *FLOUR* with confidence 0.05].\n\nHowever, if the person now decides to add flour to his/her cart, the new association rule could be as showing below, suggesting ingredients to make a cake.\n\n+ **if** bought [*EGGS, FLOUR*] **then** will buy [*SUGGAR* with confidence 0.45; BAKING POWDER with confidence 0.12; *BREAD* with confidence *0.03*].\n\nThere are many real scenarios where MBA plays a central role in data analysis, such as supermarket transactions, online orders or credit card history. Marketers may use these association rules to arrange correlated products closer to each other on store shelves or make online suggestions so that customers buy more items. Some questions that an MBA can usually help retailers to answer are:\n\n- What items are often purchased together?\n- Given a basket, what items should be suggested?\n- How should items be placed together on the shelves?\n\n### Objectif\n\nVotre objectif dans ce TP est de d\u00e9velopper un algorithme MBA pour r\u00e9v\u00e9ler les motifs en cr\u00e9ant des r\u00e8gles d'association dans un ensemble de donn\u00e9es volumineux avec plus de trois millions de transactions de supermarch\u00e9. Cependant, la collecte de r\u00e8gles d'association dans les grands ensembles de donn\u00e9es est un probl\u00e8me tr\u00e8s intensif en calcul, ce qui rend presque impossible leur ex\u00e9cution sans syst\u00e8me distribu\u00e9. Par cons\u00e9quent, pour ex\u00e9cuter votre algorithme, vous aurez acc\u00e8s \u00e0 un cluster de *cloud computing* distribu\u00e9 avec des centaines de c\u0153urs.\n\n\u00c0 cette fin, un algorithme **MapReduce** sera impl\u00e9ment\u00e9 avec le framework [Apache Spark](http://spark.apache.org), un syst\u00e8me informatique distribu\u00e9 rapide. En r\u00e9sum\u00e9, Spark est un framework open source con\u00e7u avec une m\u00e9thodologie *scale-out* qui en fait un outil tr\u00e8s puissant pour les programmeurs ou les d\u00e9veloppeurs d'applications pour effectuer un volume massif de calculs et de traitement de donn\u00e9es dans des environnements distribu\u00e9s. Spark fournit des API de haut niveau qui facilitent la cr\u00e9ation d'applications parall\u00e8les sans avoir \u00e0 se soucier de la fa\u00e7on dont votre code et vos donn\u00e9es sont parall\u00e9lis\u00e9s / distribu\u00e9s par le cluster informatique. Spark fait tout pour vous.\n\nLa mise en \u0153uvre suivra l'algorithme d'analyse du panier de march\u00e9 pr\u00e9sent\u00e9 par Jongwook Woo et Yuhang Xu (2012). L'image **workflow.pdf** illustre le flux de travail de l'algorithme et doit \u00eatre utilis\u00e9e pour consultation tout au long de ce TP. Les cases bleues sont celles o\u00f9 vous devez impl\u00e9menter une m\u00e9thode pour effectuer une fonction de mappage ou de r\u00e9duction, et les cases grises repr\u00e9sentent leur sortie attendue. **Toutes ces op\u00e9rations sont expliqu\u00e9es en d\u00e9tail dans les sections suivantes.**\n___\nYour goal in this TP is to develop an MBA algorithm for revealing patterns by creating association rules in a big dataset with more than three million supermarket transactions. However, mining association rules for large datasets is a very computationally intensive problem, which makes it almost impractical to perform it without a distributed system. Hence, to run your algorithm, you will have access to a distributed cloud computing cluster with hundreds of cores. \n\nTo this end, a **MapReduce** algorithm will be implemented upon the [Apache Spark](http://spark.apache.org) framework, a fast cluster computing system. In a nutshell, Spark is an open source framework designed with a *scale-out* methodology which makes it a very powerful tool for programmers or application developers to perform a massive volume of computations and data processing in distributed environments. Spark provides high-level APIs that make it easy to build parallel apps without needing to worry about how your code and data are parallelized/distributed thought the computing cluster. Spark does it all for you.\n\nThe implementation will follow the Market Basket Analysis algorithm presented by Jongwook Woo and Yuhang Xu (2012). The image **workflow.svg** Illustrates the algorithm's workflow, and is to be used for consultation throughout this TP. The blue boxes are the ones where you must implement a method to perform a map or reduce function, and the gray boxes represent their expected output. **All these operations are explained in detail in the following sections.**\n\n## 1. Configuration de Spark\n\nSpark fonctionne sur les syst\u00e8mes Windows et UNIX (par exemple, Linux, Mac OS). Il est facile d'ex\u00e9cuter Spark localement sur une seule machine - tout ce dont vous avez besoin est d'avoir Java install\u00e9 sur votre syst\u00e8me PATH, ou la variable d'environnement JAVA_HOME pointant vers une installation Java. Il est obligatoire que le **JDK v8** soit install\u00e9 sur votre syst\u00e8me, car Spark ne prend actuellement en charge que cette version. Si ce n'est pas le cas, acc\u00e9dez \u00e0 [la page Web de Java](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) pour t\u00e9l\u00e9charger et installer une machine virtuelle Java. N'oubliez pas de d\u00e9finir la variable d'environnement JAVA_HOME pour utiliser JDK v8 si votre installation ne le fait pas automatiquement. Mise \u00e0 jour 2022: Il est \u00e0 not\u00e9 que pour les syst\u00e8mes d'exploitation de **Google Cloud, JDK v8 n'est pas disponible. Remplacer cela par la JDK 10 (default-jdk) permet \u00e9galement \u00e0 Spark de fonctionner pour ce TP.**\n\nL'interface entre Python et Spark se fait via **PySpark**, qui peut \u00eatre install\u00e9 en ex\u00e9cutant `pip install pyspark` ou configur\u00e9 en suivant la s\u00e9quence ci-dessous:\n\n1. D'abord, allez sur http://spark.apache.org/downloads\n2. S\u00e9lectionnez la derni\u00e8re version de Spark et le package pr\u00e9-construit pour Apache Hadoop 2.7\n3. Cliquez pour t\u00e9l\u00e9charger **spark-2.4.5-bin-hadoop2.7.tgz** et d\u00e9compressez-le dans le dossier de votre choix.\n4. Ensuite, exportez les variables suivantes pour lier PYSPARK (l'interface python de Spark) \u00e0 votre distribution python dans votre fichier `~/.bash_profile`.\n\n``\nexport SPARK_HOME=/chemin/ vers / spark-2.4.5-bin-hadoop2.7\nexport PYTHONPATH=\"$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$SPARK_HOME/python/lib/pyspark.zip:$ PYTHONPATH\"\nexport PYSPARK_PYTHON=/chemin/vers/votre/python3\n``\n\n5. Ex\u00e9cutez `source ~./bash_profile` pour effectuer les modifications et red\u00e9marrer cette session de notebook jupyter.\n___\nSpark runs on both Windows and UNIX-like systems (e.g., Linux, Mac OS). It's easy to run locally on one machine \u2014 all you need is to have Java installed on your system PATH, or the JAVA_HOME environment variable pointing to a Java installation. It is mandatory that you have the **JDK v8** installed in your system, as Spark currently only support this version. If you haven't, go to [Java's web page](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) to download and install a Java Virtual Machine. Remember to set the environment variable JAVA_HOME to use JDK v8 if your installation does not do it automatically for you. **2022 update: on google cloud the operating systems does not support JDK v8. It can be replaced by the JDK v10 (default-jdk) to be able to run the TP.**\n\nThe interface between Python and Spark is done through **PySpark**, which can be installed by running `pip install pyspark` or set up following the sequence below:\n\n1. First, go to http://spark.apache.org/downloads \n2. Select the newest Spark release and the Pre-built for Apache Hadoop 2.7 package \n3. Click for download **spark-2.4.5-bin-hadoop2.7.tgz** and unzip it in any folder of your preference. \n4. Next, export the following variables to link PYSPARK (Spark's python interface) to your python distribution in your `~/.bash_profile` file.\n\n``\nexport SPARK_HOME=/path/to/spark-2.4.5-bin-hadoop2.7\nexport PYTHONPATH=\"$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$SPARK_HOME/python/lib/pyspark.zip:$PYTHONPATH\"\nexport PYSPARK_PYTHON=/path/to/your/python3\n``\n\n5. Run `source ~./bash_profile` to effectuate the changes and restart this jupyter notebook session.\n\n#### Alternative for using Google Collab\n\nSi vous pensez utiliser Google Colaboratory, ex\u00e9cutez la cellule de code suivante pour installer Spark\n___\nIf you are planning on using Google Colaboratory platform, run the following code cell to set up Spark."}, {"cell_type": "code", "execution_count": 48, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "JmUMt4htMazm", "outputId": "d891b878-7b80-4140-aed9-9285eb51a3ee"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ndefault-jdk is already the newest version (2:1.11-71).\nThe following package was automatically installed and is no longer required:\n  linux-image-4.19.0-21-cloud-amd64\nUse 'apt autoremove' to remove it.\n0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\nRequirement already satisfied: pyspark in /usr/lib/spark/python (3.1.3)\nRequirement already satisfied: py4j==0.10.9 in /opt/conda/miniconda3/lib/python3.8/site-packages (from pyspark) (0.10.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m"}], "source": "import os\n!apt install -y default-jdk\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n!pip install pyspark"}, {"cell_type": "markdown", "metadata": {"id": "rovSCW_vYs7m"}, "source": "#### Testez votre Spark / Test your Spark\n\u00c0 l'aide du code suivant, vous pouvez tester si Spark est install\u00e9 correctement.\n___\nUsing the following code, you can test if Spark is installed correctly:"}, {"cell_type": "code", "execution_count": 34, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "UxgNiBFkYs7n", "outputId": "f067d1fa-d965-42b8-ca87-891dc6f281f1"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 115:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----+\n|hello|\n+-----+\n|spark|\n+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "import pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\ndf = spark.sql(\"select 'spark' as hello \")\ndf.show()"}, {"cell_type": "markdown", "metadata": {"id": "QaYpUpOFMazu"}, "source": "### 1.1 Exemple de comptage de produits / Products Counting Example \n\nPour tester votre installation et commencer \u00e0 vous familiariser avec Spark, nous suivrons un exemple qui compte combien de fois les produits d'un toy dataset ont \u00e9t\u00e9 achet\u00e9s.\n\nLe principal point d'entr\u00e9e pour commencer la programmation avec Spark est [l'API RDD](https://spark.apache.org/docs/latest/rdd-programming-guide.html), une excellente abstraction Spark pour travailler avec MapReduce. RDD est une collection d'\u00e9l\u00e9ments partitionn\u00e9s sur les n\u0153uds du cluster qui peuvent fonctionner en parall\u00e8le. En d'autres termes, RDD est la fa\u00e7on dont Spark maintient vos donn\u00e9es pr\u00eates \u00e0 ex\u00e9cuter une fonction (par exemple, une fonction Map ou une fonction reduce) en parall\u00e8le. **Ne vous inqui\u00e9tez pas si cela semble toujours d\u00e9routant, il sera clair une fois que vous commencerez \u00e0 l'impl\u00e9menter**. Cependant, cela fait partie de ce TP d'\u00e9tudier / consulter [Spark python API](https://spark.apache.org/docs/latest/api/python/) et d'apprendre \u00e0 l'utiliser. Certaines fonctions utiles offertes par l'API RDD sont:\n___\nTo test your installation and start to get familiarized with Spark, we will follow an example that counts how many times the products of a toy dataset were purchased.\n\nThe main entry point to start programming with Spark is the [RDD API](https://spark.apache.org/docs/latest/rdd-programming-guide.html), an excellent Spark abstraction to work with the MapReduce framework.  RDD is a collection of elements partitioned across the nodes of the cluster that can operate in parallel. In other words, RDD is how Spark keeps your data ready to perform some function (e.g., a map or reduce function) in parallel. **Do not worry if this still sounds confusing, it will be clear once you start implementing**. However, it is part of this TP to study/consult the [Spark python API](https://spark.apache.org/docs/latest/api/python/) and learn how to use it. Some useful functions that the RDD API offers are:\n\n1. **map**: return a new RDD by applying a function to each element of this RDD.\n2. **flatMap**: return a new RDD by first applying a function to all elements of this RDD, and then flattening the results. **Should be used when each entry will yield more than one mapped element**\n3. **reduce**: reduces the elements of this RDD using the specified commutative and associative binary operator.\n4. **reduceByKey**: merge the values for each key using an associative and commutative reduce function\n5. **groupByKey**: group the values for each key in the RDD into a single sequence\n6. **collect**: return a list that contains all of the elements in this RDD. **Should not be used when working with a lot of data**\n7. **takeSample**: return a sampled subset of this RDD\n8. **count**: return the number of elements in this RDD.\n9. **filter**: return a new RDD containing only the elements that satisfy a predicate."}, {"cell_type": "code", "execution_count": 12, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "NZDz1nrBMazu", "outputId": "5ce06976-c1fb-405d-c079-0b588cbc33d7"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Toy dataset\n+--------+-----------+\n|order_id|transaction|\n+--------+-----------+\n|       1|    a;b;c;f|\n|       2|    d;b;a;e|\n|       3|        c;b|\n|       4|        b;c|\n+--------+-----------+\n\nToy dataframe as a RDD object (list of Row objects):\n\t [Row(order_id='1', transaction='a;b;c;f'), Row(order_id='2', transaction='d;b;a;e'), Row(order_id='3', transaction='c;b'), Row(order_id='4', transaction='b;c')]\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "\nMapped products:\n\t [('a', 1), ('b', 1), ('c', 1), ('f', 1), ('d', 1), ('b', 1), ('a', 1), ('e', 1), ('c', 1), ('b', 1), ('b', 1), ('c', 1)]\n\nReduced (merged) products:\n\t [('a', 2), ('b', 4), ('c', 3), ('f', 1), ('d', 1), ('e', 1)]\n\nVisualizing as a dataframe:\n+-------+-------------+\n|product|count_product|\n+-------+-------------+\n|      a|            2|\n|      b|            4|\n|      c|            3|\n|      f|            1|\n|      d|            1|\n|      e|            1|\n+-------+-------------+\n\n"}], "source": "from pyspark.sql import SparkSession\n\ndef map_to_product(row):\n    \"\"\"\n    Map each transaction into a set of KEY-VALUE elements.\n    The KEY is the word (product) itself and the VALUE is its number of apparitions.\n    \"\"\"\n    products = row.transaction.split(';') # split products from the column transaction\n    for p in products:\n        yield (p, 1)\n\ndef reduce_product_by_key(value1, value2):\n    \"Reduce the mapped objects to unique words by merging (summing ) their values\"\n    return value1+value2\n\n# Initializates a object of SparkSession class, main entry point to Spark's funcionalites\nspark = SparkSession.builder.getOrCreate()\n        \n# Read a toy dataset\ntoy = spark.read.csv('gs://my_bucket_tp_andi/toy.csv', header=True)\nprint(\"Toy dataset\")\ntoy.show()\n\n# Obtain a RDD object to call a map function\ntoy_rdd = toy.rdd\nprint(\"Toy dataframe as a RDD object (list of Row objects):\\n\\t\", toy_rdd.collect())\n\n# Map function to identify all products\ntoy_rdd = toy_rdd.flatMap(map_to_product)\nprint(\"\\nMapped products:\\n\\t\", toy_rdd.collect())\n\n# Reduce function to merge values of elements that share the same KEY\ntoy_rdd = toy_rdd.reduceByKey(reduce_product_by_key)\nprint(\"\\nReduced (merged) products:\\n\\t\", toy_rdd.collect())\n\nprint(\"\\nVisualizing as a dataframe:\")\ntoy_rdd.toDF([\"product\", \"count_product\"]).show()"}, {"cell_type": "markdown", "metadata": {"id": "PpJGQmzXMazz"}, "source": "### 1.2 Travailler avec Spark Dataframe / Working with Spark Dataframes\n\nDans l'exemple ci-dessus, nous avons bri\u00e8vement utilis\u00e9 une classe Dataframe de Spark, mais uniquement pour obtenir un objet RDD avec ``toy.rdd`` et pour aficher les donn\u00e9es sous forme de tableau structur\u00e9 avec le ``show ()`` une fonction. Cependant, [Dataframe](http://spark.apache.org/docs/latest/api/python/) est une partie cruciale de la version actuelle de Spark et est construit sur l'API RDD. Il s'agit d'une collection distribu\u00e9e de lignes sous des colonnes nomm\u00e9es, identique \u00e0 une table dans une base de donn\u00e9es relationnelle. Le Dataframe de Spark fonctionne de la m\u00eame mani\u00e8re que [Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). En fait, nous pouvons exporter (obtenir) une Dataframe Spark vers (\u00e0 partir de) \u200b\u200bune Dataframe pandas avec la fonction ``toPandas()``  (``spark.createDataFrame``).\n\nUne fonctionnalit\u00e9 centrale du Dataframe est de b\u00e9n\u00e9ficier du [Spark SQL](https://spark.apache.org/docs/latest/sql-programming-guide.html#sql), un module qui permet des requ\u00eates SQL sur des donn\u00e9es structur\u00e9es. Par exemple, le m\u00eame \u00ab exemple de comptage de produits \u00bb aurait pu \u00eatre impl\u00e9ment\u00e9 comme une s\u00e9quence d'op\u00e9rations SQL sur les donn\u00e9es:\n___\n\nIn the example above, we briefly used a Spark's Dataframe class, but only to obtain an RDD object with ```toy.rdd``` and to print the data as a structured table with the ```show()``` function. However, [Dataframe](http://spark.apache.org/docs/latest/api/python/) is a crucial part of the current Spark release and is built upon the RDD API. It is a distributed collection of rows under named columns, the same as a table in a relational database. Spark's Dataframe works similarly as [Pandas'](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). In fact, we can export (obtain) a Spark's dataframe to (from) a pandas' data frame with the function ```toPandas()``` (```spark.createDataFrame```).\n\nA central functionality of the data frame is to profit from the [Spark SQL](https://spark.apache.org/docs/latest/sql-programming-guide.html#sql), a module that allows SQL queries over structured data. For example, the same 'product counting example' could have been implemented as a sequence of SQL operations over the data:  "}, {"cell_type": "code", "execution_count": 35, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "oFL6BuIDMaz0", "outputId": "88e5b540-5efa-4f98-f25b-68d24c1318f0"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "New column 'products': exploding the transaction's products to a new row\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------+-----------+--------+\n|order_id|transaction|products|\n+--------+-----------+--------+\n|       1|    a;b;c;f|       a|\n|       1|    a;b;c;f|       b|\n|       1|    a;b;c;f|       c|\n|       1|    a;b;c;f|       f|\n|       2|    d;b;a;e|       d|\n|       2|    d;b;a;e|       b|\n|       2|    d;b;a;e|       a|\n|       2|    d;b;a;e|       e|\n|       3|        c;b|       c|\n|       3|        c;b|       b|\n|       4|        b;c|       b|\n|       4|        b;c|       c|\n+--------+-----------+--------+\n\nCouting unique products:\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 117:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------+-------------+\n|products|count_product|\n+--------+-------------+\n|       b|            4|\n|       c|            3|\n|       a|            2|\n|       f|            1|\n|       e|            1|\n|       d|            1|\n+--------+-------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "import pyspark.sql.functions as f\n\n# Creates a new column, products, with all products appering in each transaction\nprint('New column \\'products\\': exploding the transaction\\'s products to a new row')\ndf_toy = toy.withColumn('products', f.explode(f.split(toy.transaction, ';')))\ndf_toy.show()\n\n# Performs a select query and group rows by the product name, aggreagating by counting\nprint('Couting unique products:')\ndf_toy.select(df_toy.products)\\\n      .groupBy(df_toy.products)\\\n      .agg(f.count('products').alias('count_product'))\\\n      .sort('count_product', ascending=False)\\\n      .show()"}, {"cell_type": "markdown", "metadata": {"id": "W4HFs8CVMaz3"}, "source": "En outre, les m\u00eames op\u00e9rations SQL effectu\u00e9es ci-dessus auraient pu \u00eatre effectu\u00e9es avec une requ\u00eate en langage SQL traditionnel comme indiqu\u00e9 ci-dessous:\n___\nAlso, the same SQL operations performed above could have been done with a traditional SQL language query as showing below:"}, {"cell_type": "code", "execution_count": 49, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "O_eYl-7tMaz3", "outputId": "3c14ddb9-bce0-417d-8af9-337e09c67c3c"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+-------------+\n|products|product_count|\n+--------+-------------+\n|       b|            4|\n|       c|            3|\n|       a|            2|\n|       f|            1|\n|       e|            1|\n|       d|            1|\n+--------+-------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Creates a relational table TOY in the Spark session\ndf_toy.createOrReplaceTempView(\"TOY\")\n\nspark.sql(\"SELECT t.products, COUNT(t.products) AS product_count\"\n          \" FROM TOY t\"\n          \" GROUP BY t.products\"\n          \" ORDER BY product_count DESC\").show()"}, {"cell_type": "markdown", "metadata": {"id": "MTMT2RlqQBj9"}, "source": "Ces concepts SQL sont mentionn\u00e9s ici car ils nous seront utiles lors du TP, principalement dans la section 3, pour manipuler les donn\u00e9es du supermarch\u00e9, qui sont structur\u00e9es en tableaux. Ainsi, si vous n'\u00eates pas familier avec SQL, il est recommand\u00e9 de suivre un [tutoriel](https://www.w3schools.com/sql/) pour comprendre les bases.\n___\nThese SQL concepts are being mentioned here because they will be useful to us during the TP, mainly in Section 3, to manipulate the supermarket data, which is structured in tables. Thus, if you are not familiar with SQL, it is recommended that you follow a [tutorial](https://www.w3schools.com/sql/) to understand the basics."}, {"cell_type": "markdown", "metadata": {"id": "s1oZzC-ZQEE0"}, "source": "\n\n## 2. Algorithme MBA (45 points)\nLes sections suivantes expliquent comment d\u00e9velopper chaque \u00e9tape de l'algorithme MapReduce pour notre application de supermarch\u00e9. La figure workflow.pdf illustre chaque \u00e9tape de l'algorithme.\n___\nThe following sections explain how you should develop each step of the MapReduce algorithm for our supermarket application. Figure workflow.png illustrates each step of the algorithm."}, {"cell_type": "markdown", "metadata": {"id": "T0Onr2NxMaz8"}, "source": "\n\n### 2.1 Map to Patterns / Map to Patterns (10 points)\nPour un sous-ensemble de transactions (c'est-\u00e0-dire les lignes de notre toy dataset), chaque transaction doit \u00eatre **mapp\u00e9e** vers un ensemble de *motifs d'achat* trouv\u00e9s dans la transaction. Formellement, ces motifs sont des sous-ensembles de produits qui repr\u00e9sentent un groupe d'articles achet\u00e9s ensemble. \n\nPour le framework MapReduce, chaque motif doit \u00eatre cr\u00e9\u00e9 comme un \u00e9l\u00e9ment *KEY-VALUE*, o\u00f9 la KEY peut prendre la forme d'un singleton, d'une paire ou d'un trio de produits pr\u00e9sents dans la transaction. Plus pr\u00e9cis\u00e9ment, pour chaque transaction, la fonction de mappage doit g\u00e9n\u00e9rer tous les sous-ensembles **UNIQUE** possibles de taille **UN, DEUX ou TROIS**. La VALEUR associ\u00e9e \u00e0 chaque KEY est le nombre de fois que la KEY est apparue dans la transaction (si nous supposons qu'aucun produit n'appara\u00eet plus d'une fois dans la transaction, cette valeur est toujours \u00e9gale \u00e0 un).\n\nMaintenant, impl\u00e9mentez la fonction **map_to_patterns** qui re\u00e7oit une transaction (une ligne du dataset) et retourne les motifs trouv\u00e9s dans la transaction. Les \u00e9l\u00e9ments mapp\u00e9s sont un tuple (KEY, VALUE), o\u00f9 KEY est \u00e9galement un tuple de noms de produits. Il est crucial de noter que, puisque chaque entr\u00e9e (transaction) de la fonction MAP produira **plus** un \u00e9l\u00e9ment KEY-VALUE, un *flatMap* doit \u00eatre invoqu\u00e9 pour cette \u00e9tape.\n\nPour le toy dataset, la sortie attendue est similaire \u00e0:\n___\nFor a given set of transactions (i.e., the rows of our toy dataset), each transaction must be **mapped** into a set of *purchase patterns* found within the transaction. Formally, these patterns are subsets of products that represent a group of items bought together. \n\nFor the MapReduce framework, each pattern must be created as a *KEY-VALUE* element, where the KEY can take the form of a singleton, a pair or a trio of products that are present in the transaction. More precisely, for each transaction, the mapping function must generate all possible **UNIQUE** subsets of size **ONE, TWO or THREE**.  The VALUE associated with each KEY is the number of times that the KEY appeared in the transaction (if we assume that no product appears more than once in the transaction, this value is always equal to one). \n\nNow, implement the **map_to_patterns** function that receives a transaction (a row from the data frame) and returns the patterns found in the transaction. The mapped elements are a tuple (KEY, VALUE), where KEY is also a tuple of product names. It is crucial to notice that, since each entry (transaction) of the map function will **yield** more than one KEY-VALUE element, a *flatMap* must be invoked for this step.\n\nFor the toy dataset, the expected output is similar to:\n\n\n\n<pre style=\"align:center; border:1px solid black;font-size: 8pt; line-height: 1.1; height: auto; width: 20em; padding-left:1px\">\n<code>\n+---------------+-----------+\n|       patterns|occurrences|\n+---------------+-----------+\n|         ('a',)|          1|\n|     ('a', 'b')|          1|\n|('a', 'b', 'c')|          1|\n|('a', 'b', 'f')|          1|\n|     ('a', 'c')|          1|\n|('a', 'c', 'f')|          1|\n|     ('a', 'f')|          1|\n|         ('b',)|          1|\n|     ('b', 'c')|          1|\n|('b', 'c', 'f')|          1|\n|     ('b', 'f')|          1|\n|         ('c',)|          1|\n|     ('c', 'f')|          1|\n|         ('f',)|          1|\n|         ('a',)|          1|\n|     ('a', 'b')|          1|\n|('a', 'b', 'd')|          1|\n|('a', 'b', 'e')|          1|\n|     ('a', 'd')|          1|\n|('a', 'd', 'e')|          1|\n|     ('a', 'e')|          1|\n|         ('b',)|          1|\n|     ('b', 'd')|          1|\n|('b', 'd', 'e')|          1|\n|     ('b', 'e')|          1|\n|         ('d',)|          1|\n|     ('d', 'e')|          1|\n|         ('e',)|          1|\n|         ('b',)|          1|\n|     ('b', 'c')|          1|\n|         ('c',)|          1|\n|         ('b',)|          1|\n|     ('b', 'c')|          1|\n|         ('c',)|          1|\n+---------------+-----------+\n</code>\n</pre>"}, {"cell_type": "code", "execution_count": 37, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "BscKKDAjMaz9", "outputId": "83713db8-5341-4b01-ce9b-6acffe64781c"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 123:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------+-----------+\n|       patterns|occurrences|\n+---------------+-----------+\n|         ('a',)|          1|\n|         ('b',)|          1|\n|         ('c',)|          1|\n|         ('f',)|          1|\n|     ('a', 'b')|          1|\n|     ('a', 'c')|          1|\n|     ('a', 'f')|          1|\n|     ('b', 'c')|          1|\n|     ('b', 'f')|          1|\n|     ('c', 'f')|          1|\n|('a', 'b', 'c')|          1|\n|('a', 'b', 'f')|          1|\n|('a', 'c', 'f')|          1|\n|('b', 'c', 'f')|          1|\n|         ('a',)|          1|\n|         ('b',)|          1|\n|         ('d',)|          1|\n|         ('e',)|          1|\n|     ('a', 'b')|          1|\n|     ('a', 'd')|          1|\n|     ('a', 'e')|          1|\n|     ('b', 'd')|          1|\n|     ('b', 'e')|          1|\n|     ('d', 'e')|          1|\n|('a', 'b', 'd')|          1|\n|('a', 'b', 'e')|          1|\n|('a', 'd', 'e')|          1|\n|('b', 'd', 'e')|          1|\n|         ('b',)|          1|\n|         ('c',)|          1|\n|     ('b', 'c')|          1|\n|         ('b',)|          1|\n|         ('c',)|          1|\n|     ('b', 'c')|          1|\n+---------------+-----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Source:  https://www.geeksforgeeks.org/itertools-combinations-module-python-print-possible-combinations/\nfrom itertools import combinations # Generates all the combinations for the array elements.\n\ndef format_tuples(pattern):\n    \"\"\"\n    Used for visualizition.\n    Transforms tuples to a string since Dataframe does not support column of tuples with different sizes\n    (a,b,c) -> '(a,b,c)'\n    \"\"\"\n    return (str(pattern[0]), str(pattern[1]))\n\ndef map_to_patterns(row):\n    \n    transaction_products = row.transaction.split(';')\n    keys = []\n    transaction_products.sort()\n\n    for i in range(1,4):\n        for element in list(combinations(transaction_products, i)):\n            keys.append(element)\n\n    for patterns in keys:\n        yield (patterns, 1)\n\ntoy_rdd = toy.rdd\npatterns_rdd = toy_rdd.flatMap(map_to_patterns)\n\n# Output as dataframe\npatterns_rdd.map(format_tuples).toDF(['patterns', 'occurrences']).show(50)"}, {"cell_type": "markdown", "metadata": {"id": "YvvRw0plMa0B"}, "source": "### 2.2  Reduce patterns  (2,5 points)\nUne fois que diff\u00e9rents processeurs ont trait\u00e9 les transactions, une fonction **reduce** doit \u00eatre appel\u00e9e pour combiner des KEYS identiques (le sous-ensemble de produits) et calculer le nombre total de ses occurrences dans le dataset. En d'autres termes, cette proc\u00e9dure de r\u00e9duction doit additionner la *VALUE* de chaque KEY identique.\n\nCr\u00e9ez ci-dessous une fonction **reduce_patterns** qui doit additionner la VALUE de chaque motif.\nPour le toy dataset, la sortie attendue est:\n___\nOnce different CPUs processed the transactions, a **reduce** function must take place to combine identical KEYS (the subset of products) and compute the total number of its occurrences in the entire dataset. In other words, this reduce procedure must sum the *VALUE* of each identical KEY.\n\nCreate a **reduce_patterns** function below that must sum the VALUE of each pattern.\nFor the toy dataset, the expected output is:\n\n<pre style=\"align:center; border:1px solid black;font-size: 8pt; line-height: 1.1; height: auto; width: 28em; padding-left:5px\">\n<code>\n+---------------+--------------------+\n|       patterns|combined_occurrences|\n+---------------+--------------------+\n|         ('a',)|                   2|\n|     ('a', 'b')|                   2|\n|('a', 'b', 'c')|                   1|\n|('a', 'b', 'f')|                   1|\n|     ('a', 'c')|                   1|\n|('a', 'c', 'f')|                   1|\n|     ('a', 'f')|                   1|\n|         ('b',)|                   4|\n|     ('b', 'c')|                   3|\n|('b', 'c', 'f')|                   1|\n|     ('b', 'f')|                   1|\n|         ('c',)|                   3|\n|     ('c', 'f')|                   1|\n|         ('f',)|                   1|\n|('a', 'b', 'd')|                   1|\n|('a', 'b', 'e')|                   1|\n|     ('a', 'd')|                   1|\n|('a', 'd', 'e')|                   1|\n|     ('a', 'e')|                   1|\n|     ('b', 'd')|                   1|\n|('b', 'd', 'e')|                   1|\n|     ('b', 'e')|                   1|\n|         ('d',)|                   1|\n|     ('d', 'e')|                   1|\n|         ('e',)|                   1|\n+---------------+--------------------+\n</code>\n</pre>\n"}, {"cell_type": "code", "execution_count": 50, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "67IKY_4MMa0C", "outputId": "22845066-30d6-4e21-8225-11df831d7498"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 208:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------+--------------------+\n|       patterns|combined_occurrences|\n+---------------+--------------------+\n|         ('a',)|                   2|\n|         ('b',)|                   4|\n|         ('c',)|                   3|\n|         ('f',)|                   1|\n|     ('a', 'b')|                   2|\n|     ('a', 'c')|                   1|\n|     ('a', 'f')|                   1|\n|     ('b', 'c')|                   3|\n|     ('b', 'f')|                   1|\n|     ('c', 'f')|                   1|\n|('a', 'b', 'c')|                   1|\n|('a', 'b', 'f')|                   1|\n|('a', 'c', 'f')|                   1|\n|('b', 'c', 'f')|                   1|\n|         ('d',)|                   1|\n|         ('e',)|                   1|\n|     ('a', 'd')|                   1|\n|     ('a', 'e')|                   1|\n|     ('b', 'd')|                   1|\n|     ('b', 'e')|                   1|\n|     ('d', 'e')|                   1|\n|('a', 'b', 'd')|                   1|\n|('a', 'b', 'e')|                   1|\n|('a', 'd', 'e')|                   1|\n|('b', 'd', 'e')|                   1|\n+---------------+--------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "def reduce_patterns(first_key_value,second_key_value):\n    return first_key_value + second_key_value\n\ncombined_patterns_rdd = patterns_rdd.reduceByKey(reduce_patterns)\n\n# Output as dataframe\ncombined_patterns_rdd.map(format_tuples).toDF(['patterns', 'combined_occurrences']).show(100)"}, {"cell_type": "markdown", "metadata": {"id": "6BME1VugMa0F"}, "source": "### 2.3 Map to subpatterns (15 points)\nEnsuite, une autre fonction **map** doit \u00eatre appliqu\u00e9e pour g\u00e9n\u00e9rer des sous-motifs. Encore une fois, les sous-motifs sont des \u00e9l\u00e9ments KEY-VALUE, o\u00f9 la KEY est \u00e9galement un sous-ensemble de produits. Cependant, la cr\u00e9ation de la KEY du sous-motif est une proc\u00e9dure diff\u00e9rente. Cette fois, l'id\u00e9e est de d\u00e9composer la liste des produits de chaque motif (KEY), de supprimer un produit \u00e0 la fois et de produire la liste r\u00e9sultante en tant que nouvelle cl\u00e9 de sous-motif.\n\nPar exemple, pour un mod\u00e8le donn\u00e9 $P$ avec trois produits, $p_1, p_2$ et $p_3$, trois nouvelles cl\u00e9s de sous-motifs vont \u00eatre cr\u00e9\u00e9es: (i) supprimer $p_1$ et retourner ($p_2, p_3$) ; (ii) supprimer $p_2$ et retourner ($p_1, p_3$); et (iii) supprimer $p_3$ et retourner ($p_1, p_2$).\n\nDe plus, la structure VALUE du sous-motif sera \u00e9galement diff\u00e9rente. Au lieu d'une seule valeur enti\u00e8re unique comme nous l'avons eu dans les motifs, cette fois un *tuple* devrait \u00eatre cr\u00e9\u00e9 pour le sous-motif VALUE. Ce tuple contient le produit qui a \u00e9t\u00e9 retir\u00e9 lors de la remise de la KEY et le nombre de fois que le motif est apparu. Par exemple ci-dessus, les valeurs doivent \u00eatre ($p_1,v$), ($p_2,v$) et ($p_3,v $), respectivement, o\u00f9 $v$ est la VALEUR du motif.\n\nL'id\u00e9e derri\u00e8re les sous-motif est de cr\u00e9er **des r\u00e8gles** telles que : lorsque les produits de KEY ont \u00e9t\u00e9 achet\u00e9s, l'article pr\u00e9sent dans la VALEUR a \u00e9galement \u00e9t\u00e9 achet\u00e9 *v* fois. En outre, chaque motif doit \u00e9galement produire un sous-motif dans lequel la cl\u00e9 est la m\u00eame liste de produits du motif, mais la valeur est un tuple avec un produit nul (None) et le nombre de fois que le motif est apparu. Cet \u00e9l\u00e9ment sera utile pour garder une trace du nombre de fois o\u00f9 un tel motif a \u00e9t\u00e9 trouv\u00e9 et sera utilis\u00e9 ult\u00e9rieurement pour calculer la valeur de confiance lors de la g\u00e9n\u00e9ration des r\u00e8gles d'association.\n\nMaintenant, impl\u00e9mentez la fonction **map_to_subpatterns** qui re\u00e7oit un motif et produit tous les sous-motif trouv\u00e9s. Encore une fois, chaque entr\u00e9e (motif) g\u00e9n\u00e9rera plus d'un \u00e9l\u00e9ment KEY-VALUE, puis une fonction flatMap doit \u00eatre appel\u00e9e.\n\nPour le toy dataset, la sortie attendue est:\n___\nNext, another **map** function should be applied to generate subpatterns. Once again, the subpatterns are KEY-VALUE elements, where the KEY is a subset of products as well. However, creating the subpattern's KEY is a different procedure. This time, the idea is to break down the list of products of each pattern (pattern KEY), remove one product at a time, and yield the resulting list as the new subpattern KEY. \n\nFor example, for a given pattern $P$ with three products, $p_1, p_2 $ and $p_3$, three new subpatterns KEYs are going to be created: (i) remove $p_1$ and yield ($p_2, p_3$); (ii) remove $p_2$ and yield ($p_1,p_3$); and (iii) remove $p_3$ and yield ($p_1,p_2$). \n\nAdditionally, the subpattern's VALUE structure will also be different. Instead of just single integer value as we had in the patterns, this time a *tuple* should be created for the subpattern VALUE. This tuple contains the product that was removed when yielding the KEY and the number of times the pattern appeared. For example above, the values should be ($p_1,v$), ($p_2,v$) and ($p_3,v$), respectively, where $v$ is the VALUE of the pattern. \n\nThe idea behind subpatterns is to create **rules** such as: when the products of KEY were bought, the item present in the VALUE was also bought *v* times. Furthermore, each pattern should also yield a subpattern where the KEY is the same list of products of the pattern, but the VALUE is a tuple with a null product (None) and the number of times the pattern appeared. This element will be useful to keep track of how many times such a pattern was found and later will be used to compute the confidence value when generating the association rules. \n\nNow, implement the  **map_to_subpatterns** function that receives a pattern and yields all found subpatterns. Once again, each entry (pattern) will generate more than one KEY-VALUE element, then a flatMap function must be called.\n\nFor the toy dataset, the expected output is:\n\n<pre style=\"align:center; border:1px solid black;font-size: 8pt; line-height: 1.1; height: auto; width: 20em; padding-left:5px\">\n<code>\n+---------------+---------+\n|    subpatterns|    rules|\n+---------------+---------+\n|         ('a',)|(None, 2)|\n|     ('a', 'b')|(None, 2)|\n|         ('b',)| ('a', 2)|\n|         ('a',)| ('b', 2)|\n|('a', 'b', 'c')|(None, 1)|\n|     ('b', 'c')| ('a', 1)|\n|     ('a', 'c')| ('b', 1)|\n|     ('a', 'b')| ('c', 1)|\n|('a', 'b', 'f')|(None, 1)|\n|     ('b', 'f')| ('a', 1)|\n|     ('a', 'f')| ('b', 1)|\n|     ('a', 'b')| ('f', 1)|\n|     ('a', 'c')|(None, 1)|\n|         ('c',)| ('a', 1)|\n|         ('a',)| ('c', 1)|\n|('a', 'c', 'f')|(None, 1)|\n|     ('c', 'f')| ('a', 1)|\n|     ('a', 'f')| ('c', 1)|\n|     ('a', 'c')| ('f', 1)|\n|     ('a', 'f')|(None, 1)|\n|         ('f',)| ('a', 1)|\n|         ('a',)| ('f', 1)|\n|         ('b',)|(None, 4)|\n|     ('b', 'c')|(None, 3)|\n|         ('c',)| ('b', 3)|\n|         ('b',)| ('c', 3)|\n|('b', 'c', 'f')|(None, 1)|\n|     ('c', 'f')| ('b', 1)|\n|     ('b', 'f')| ('c', 1)|\n|     ('b', 'c')| ('f', 1)|\n|     ('b', 'f')|(None, 1)|\n|         ('f',)| ('b', 1)|\n|         ('b',)| ('f', 1)|\n|         ('c',)|(None, 3)|\n|     ('c', 'f')|(None, 1)|\n|         ('f',)| ('c', 1)|\n|         ('c',)| ('f', 1)|\n|         ('f',)|(None, 1)|\n|('a', 'b', 'd')|(None, 1)|\n|     ('b', 'd')| ('a', 1)|\n|     ('a', 'd')| ('b', 1)|\n|     ('a', 'b')| ('d', 1)|\n|('a', 'b', 'e')|(None, 1)|\n|     ('b', 'e')| ('a', 1)|\n|     ('a', 'e')| ('b', 1)|\n|     ('a', 'b')| ('e', 1)|\n|     ('a', 'd')|(None, 1)|\n|         ('d',)| ('a', 1)|\n|         ('a',)| ('d', 1)|\n|('a', 'd', 'e')|(None, 1)|\n|     ('d', 'e')| ('a', 1)|\n|     ('a', 'e')| ('d', 1)|\n|     ('a', 'd')| ('e', 1)|\n|     ('a', 'e')|(None, 1)|\n|         ('e',)| ('a', 1)|\n|         ('a',)| ('e', 1)|\n|     ('b', 'd')|(None, 1)|\n|         ('d',)| ('b', 1)|\n|         ('b',)| ('d', 1)|\n|('b', 'd', 'e')|(None, 1)|\n|     ('d', 'e')| ('b', 1)|\n|     ('b', 'e')| ('d', 1)|\n|     ('b', 'd')| ('e', 1)|\n|     ('b', 'e')|(None, 1)|\n|         ('e',)| ('b', 1)|\n|         ('b',)| ('e', 1)|\n|         ('d',)|(None, 1)|\n|     ('d', 'e')|(None, 1)|\n|         ('e',)| ('d', 1)|\n|         ('d',)| ('e', 1)|\n|         ('e',)|(None, 1)|\n+---------------+---------+\n</code>\n</pre>"}, {"cell_type": "code", "execution_count": 51, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "t8aLrdMuMa0G", "outputId": "d317538c-6da4-47be-9fb9-52e8907a99c3"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+---------+\n|    subpatterns|    rules|\n+---------------+---------+\n|         ('a',)|(None, 2)|\n|         ('b',)|(None, 4)|\n|         ('c',)|(None, 3)|\n|         ('f',)|(None, 1)|\n|     ('a', 'b')|(None, 2)|\n|         ('b',)| ('a', 2)|\n|         ('a',)| ('b', 2)|\n|     ('a', 'c')|(None, 1)|\n|         ('c',)| ('a', 1)|\n|         ('a',)| ('c', 1)|\n|     ('a', 'f')|(None, 1)|\n|         ('f',)| ('a', 1)|\n|         ('a',)| ('f', 1)|\n|     ('b', 'c')|(None, 3)|\n|         ('c',)| ('b', 3)|\n|         ('b',)| ('c', 3)|\n|     ('b', 'f')|(None, 1)|\n|         ('f',)| ('b', 1)|\n|         ('b',)| ('f', 1)|\n|     ('c', 'f')|(None, 1)|\n|         ('f',)| ('c', 1)|\n|         ('c',)| ('f', 1)|\n|('a', 'b', 'c')|(None, 1)|\n|     ('b', 'c')| ('a', 1)|\n|     ('a', 'c')| ('b', 1)|\n|     ('a', 'b')| ('c', 1)|\n|('a', 'b', 'f')|(None, 1)|\n|     ('b', 'f')| ('a', 1)|\n|     ('a', 'f')| ('b', 1)|\n|     ('a', 'b')| ('f', 1)|\n|('a', 'c', 'f')|(None, 1)|\n|     ('c', 'f')| ('a', 1)|\n|     ('a', 'f')| ('c', 1)|\n|     ('a', 'c')| ('f', 1)|\n|('b', 'c', 'f')|(None, 1)|\n|     ('c', 'f')| ('b', 1)|\n|     ('b', 'f')| ('c', 1)|\n|     ('b', 'c')| ('f', 1)|\n|         ('d',)|(None, 1)|\n|         ('e',)|(None, 1)|\n|     ('a', 'd')|(None, 1)|\n|         ('d',)| ('a', 1)|\n|         ('a',)| ('d', 1)|\n|     ('a', 'e')|(None, 1)|\n|         ('e',)| ('a', 1)|\n|         ('a',)| ('e', 1)|\n|     ('b', 'd')|(None, 1)|\n|         ('d',)| ('b', 1)|\n|         ('b',)| ('d', 1)|\n|     ('b', 'e')|(None, 1)|\n|         ('e',)| ('b', 1)|\n|         ('b',)| ('e', 1)|\n|     ('d', 'e')|(None, 1)|\n|         ('e',)| ('d', 1)|\n|         ('d',)| ('e', 1)|\n|('a', 'b', 'd')|(None, 1)|\n|     ('b', 'd')| ('a', 1)|\n|     ('a', 'd')| ('b', 1)|\n|     ('a', 'b')| ('d', 1)|\n|('a', 'b', 'e')|(None, 1)|\n|     ('b', 'e')| ('a', 1)|\n|     ('a', 'e')| ('b', 1)|\n|     ('a', 'b')| ('e', 1)|\n|('a', 'd', 'e')|(None, 1)|\n|     ('d', 'e')| ('a', 1)|\n|     ('a', 'e')| ('d', 1)|\n|     ('a', 'd')| ('e', 1)|\n|('b', 'd', 'e')|(None, 1)|\n|     ('d', 'e')| ('b', 1)|\n|     ('b', 'e')| ('d', 1)|\n|     ('b', 'd')| ('e', 1)|\n+---------------+---------+\n\n"}], "source": "from copy import deepcopy\n\ndef map_to_subpatterns(pattern):\n    key, value = pattern\n\n    yield(key, tuple((None, value)))\n    \n    if len(key) == 1:\n        return;\n    \n    key_copy = deepcopy(key)\n    for index, element in enumerate(key_copy):\n        subpattern = key_copy[0:index] + key_copy[index+1:]\n        yield(subpattern,tuple((element, value)))\n\nsubpatterns_rdd = combined_patterns_rdd.flatMap(map_to_subpatterns)\n\n# Output as dataframe\nsubpatterns_rdd.map(format_tuples).toDF(['subpatterns', 'rules']).show(100)"}, {"cell_type": "markdown", "metadata": {"id": "jl6TWh8rMa0J"}, "source": "### 2.4 Reduce Subpatterns (2.5 points)\n\nEncore une fois, une fonction **reduce** est n\u00e9cessaire pour regrouper tous les sous-motif par leur KEY. L'objectif de cette proc\u00e9dure de r\u00e9duction est de cr\u00e9er une liste de toutes les **r\u00e8gles** apparues dans KEY. Par cons\u00e9quent, la sortie attendue r\u00e9sultant de cette fonction de r\u00e9duction est \u00e9galement un \u00e9l\u00e9ment KEY-VALUE, o\u00f9 la cl\u00e9 est la KEY du sous-motif et la valeur est un groupe contenant toutes les valeurs des sous-motif qui partagent la m\u00eame cl\u00e9.\n\nPour le toy dataset, la sortie attendue est:\n___\nOnce again, a **reduce** function will be required to group all the subpatterns by their KEY. The objective of this reducing procedure is to create a list of all **rules** that appeared in KEY. Hence, the expected output resulting from this reduce function is also a KEY-VALUE element, where the KEY is the subpattern's KEY, and the VALUE is a group containing all the VALUEs of the subpatterns that share the same KEY.\n\nFor the toy dataset, the expected output is:\n\n\n<pre style=\"align:center; border:1px solid black;font-size: 8pt; line-height: 1.1; height: auto; width: 50em; padding-left:5px\">\n<code>\n+---------------+-------------------------------------------------------------+\n|subpatterns    |combined_rules                                               |\n+---------------+-------------------------------------------------------------+\n|('a',)         |[(None, 2), ('b', 2), ('c', 1), ('f', 1), ('d', 1), ('e', 1)]|\n|('a', 'b')     |[(None, 2), ('c', 1), ('f', 1), ('d', 1), ('e', 1)]          |\n|('b',)         |[('a', 2), (None, 4), ('c', 3), ('f', 1), ('d', 1), ('e', 1)]|\n|('a', 'b', 'c')|[(None, 1)]                                                  |\n|('b', 'c')     |[('a', 1), (None, 3), ('f', 1)]                              |\n|('a', 'c')     |[('b', 1), (None, 1), ('f', 1)]                              |\n|('a', 'b', 'f')|[(None, 1)]                                                  |\n|('b', 'f')     |[('a', 1), ('c', 1), (None, 1)]                              |\n|('a', 'f')     |[('b', 1), ('c', 1), (None, 1)]                              |\n|('c',)         |[('a', 1), ('b', 3), (None, 3), ('f', 1)]                    |\n|('a', 'c', 'f')|[(None, 1)]                                                  |\n|('c', 'f')     |[('a', 1), ('b', 1), (None, 1)]                              |\n|('f',)         |[('a', 1), ('b', 1), ('c', 1), (None, 1)]                    |\n|('b', 'c', 'f')|[(None, 1)]                                                  |\n|('a', 'b', 'd')|[(None, 1)]                                                  |\n|('b', 'd')     |[('a', 1), (None, 1), ('e', 1)]                              |\n|('a', 'd')     |[('b', 1), (None, 1), ('e', 1)]                              |\n|('a', 'b', 'e')|[(None, 1)]                                                  |\n|('b', 'e')     |[('a', 1), ('d', 1), (None, 1)]                              |\n|('a', 'e')     |[('b', 1), ('d', 1), (None, 1)]                              |\n+---------------+-------------------------------------------------------------+\n</code>\n</pre>\n"}, {"cell_type": "code", "execution_count": 52, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "LOP-SVIhMa0J", "outputId": "a8e8e437-f4c9-4ad6-9b25-13dc3db2d9d3", "scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+-------------------------------------------------------------+\n|subpatterns    |combined_rules                                               |\n+---------------+-------------------------------------------------------------+\n|('a',)         |[(None, 2), ('b', 2), ('c', 1), ('f', 1), ('d', 1), ('e', 1)]|\n|('b',)         |[(None, 4), ('a', 2), ('c', 3), ('f', 1), ('d', 1), ('e', 1)]|\n|('c',)         |[(None, 3), ('a', 1), ('b', 3), ('f', 1)]                    |\n|('f',)         |[(None, 1), ('a', 1), ('b', 1), ('c', 1)]                    |\n|('a', 'b')     |[(None, 2), ('c', 1), ('f', 1), ('d', 1), ('e', 1)]          |\n|('a', 'c')     |[(None, 1), ('b', 1), ('f', 1)]                              |\n|('a', 'f')     |[(None, 1), ('b', 1), ('c', 1)]                              |\n|('b', 'c')     |[(None, 3), ('a', 1), ('f', 1)]                              |\n|('b', 'f')     |[(None, 1), ('a', 1), ('c', 1)]                              |\n|('c', 'f')     |[(None, 1), ('a', 1), ('b', 1)]                              |\n|('a', 'b', 'c')|[(None, 1)]                                                  |\n|('a', 'b', 'f')|[(None, 1)]                                                  |\n|('a', 'c', 'f')|[(None, 1)]                                                  |\n|('b', 'c', 'f')|[(None, 1)]                                                  |\n|('d',)         |[(None, 1), ('a', 1), ('b', 1), ('e', 1)]                    |\n|('e',)         |[(None, 1), ('a', 1), ('b', 1), ('d', 1)]                    |\n|('a', 'd')     |[(None, 1), ('b', 1), ('e', 1)]                              |\n|('a', 'e')     |[(None, 1), ('b', 1), ('d', 1)]                              |\n|('b', 'd')     |[(None, 1), ('a', 1), ('e', 1)]                              |\n|('b', 'e')     |[(None, 1), ('a', 1), ('d', 1)]                              |\n+---------------+-------------------------------------------------------------+\nonly showing top 20 rows\n\n"}], "source": "combined_rules = subpatterns_rdd.groupByKey().mapValues(list)\n\n# Output as dataframe\ncombined_rules.map(format_tuples).toDF(['subpatterns', 'combined_rules']).show(truncate=False)"}, {"cell_type": "markdown", "metadata": {"id": "Uh69x3a8Ma0P"}, "source": "### 2.5. Map to Association Rules (15 points)\n\nEnfin, la derni\u00e8re \u00e9tape de l'algorithme consiste \u00e0 cr\u00e9er les r\u00e8gles d'association pour effectuer la MBA. Le but de cette fonction Map est de calculer le niveau **de confiance** de l'achat d'un produit, sachant qu'il y a d\u00e9j\u00e0 un ensemble de produits dans le panier. Ainsi, la KEY du sous-motif est l'ensemble des produits plac\u00e9s dans le panier et, pour chaque produit pr\u00e9sent dans la liste des r\u00e8gles, c'est-\u00e0-dire dans la VALEUR, la confiance peut \u00eatre calcul\u00e9e comme :\n\n\\begin{align*}\n\\frac{\\text{nombre de fois o\u00f9 le produit a \u00e9t\u00e9 achet\u00e9 avec KEY}}{\\text{nombre de fois o\u00f9 la KEY est apparue}}\n\\end{align*}\n\nPour l'exemple donn\u00e9 dans la figure \"workflow\", *le caf\u00e9* a \u00e9t\u00e9 achet\u00e9 20 fois et, dans 17 d'entre eux, le *lait* a \u00e9t\u00e9 achet\u00e9 ensemble. Ensuite, le niveau de confiance pour acheter du *lait* sachant que *le caf\u00e9* est dans le panier est $\\frac{17}{20}=0,85$, ce qui signifie que dans 85% des cas o\u00f9 le caf\u00e9 a \u00e9t\u00e9 achet\u00e9, le lait a aussi \u00e9t\u00e9 achet\u00e9.\n\nImpl\u00e9mentez la fonction **map_to_assoc_rules** qui calcule le niveau de confiance pour chaque sous-motif.\n\nPour le toy dataset, la sortie attendue est:\n___\nFinally, the last step of the algorithm is to create the association rules to perform the market basket analysis. The goal of this map function is to calculate the **confidence** level of buying a product, knowing that there is already a set of products in the basket. Thus, the KEY of the subpattern is the set of products placed in the basket and, for each product present in the list of rules, i.e., in the VALUE, the confidence can be calculated as:\n\n\\begin{align*}\n\\frac{\\text{number of times the product was bought together with KEY }}{\\text{number of times the KEY appeared}}\n\\end{align*}\n\nFor the example given in the Figure workflow, *coffee* was bought 20 times and, in 17 of them, *milk* was bought together. Then, the confidence level of buying *milk* knowing that *coffee* is in the basket is $\\frac{17}{20} = 0.85$, which means that in 85% of the times the coffee was bought, milk was purchased as well.\n\nImplement the **map_to_assoc_rules** function that calculates the confidence level for each subpattern.\n\nFor the toy dataset, the expected output is:\n<pre style=\"align:center; border:1px solid black;font-size: 8pt; line-height: 1.1; height: auto; width: 57em; padding-left:5px\">\n<code>\n+---------------+------------------------------------------------------------------+\n|patterns       |association_rules                                                 |\n+---------------+------------------------------------------------------------------+\n|('a',)         |[('b', 1.0), ('c', 0.5), ('f', 0.5), ('d', 0.5), ('e', 0.5)]      |\n|('a', 'b')     |[('c', 0.5), ('f', 0.5), ('d', 0.5), ('e', 0.5)]                  |\n|('b',)         |[('a', 0.5), ('c', 0.75), ('f', 0.25), ('d', 0.25), ('e', 0.25)]  |\n|('a', 'b', 'c')|[]                                                                |\n|('b', 'c')     |[('a', 0.3333333333333333), ('f', 0.3333333333333333)]            |\n|('a', 'c')     |[('b', 1.0), ('f', 1.0)]                                          |\n|('a', 'b', 'f')|[]                                                                |\n|('b', 'f')     |[('a', 1.0), ('c', 1.0)]                                          |\n|('a', 'f')     |[('b', 1.0), ('c', 1.0)]                                          |\n|('c',)         |[('a', 0.3333333333333333), ('b', 1.0), ('f', 0.3333333333333333)]|\n|('a', 'c', 'f')|[]                                                                |\n|('c', 'f')     |[('a', 1.0), ('b', 1.0)]                                          |\n|('f',)         |[('a', 1.0), ('b', 1.0), ('c', 1.0)]                              |\n|('b', 'c', 'f')|[]                                                                |\n|('a', 'b', 'd')|[]                                                                |\n|('b', 'd')     |[('a', 1.0), ('e', 1.0)]                                          |\n|('a', 'd')     |[('b', 1.0), ('e', 1.0)]                                          |\n|('a', 'b', 'e')|[]                                                                |\n|('b', 'e')     |[('a', 1.0), ('d', 1.0)]                                          |\n|('a', 'e')     |[('b', 1.0), ('d', 1.0)]                                          |\n+---------------+------------------------------------------------------------------+\n</code>\n</pre>"}, {"cell_type": "code", "execution_count": 53, "metadata": {"id": "DPrbn5CfMa0P"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+------------------------------------------------------------------+\n|patterns       |association_rules                                                 |\n+---------------+------------------------------------------------------------------+\n|('a',)         |[('b', 1.0), ('c', 0.5), ('f', 0.5), ('d', 0.5), ('e', 0.5)]      |\n|('b',)         |[('a', 0.5), ('c', 0.75), ('f', 0.25), ('d', 0.25), ('e', 0.25)]  |\n|('c',)         |[('a', 0.3333333333333333), ('b', 1.0), ('f', 0.3333333333333333)]|\n|('f',)         |[('a', 1.0), ('b', 1.0), ('c', 1.0)]                              |\n|('a', 'b')     |[('c', 0.5), ('f', 0.5), ('d', 0.5), ('e', 0.5)]                  |\n|('a', 'c')     |[('b', 1.0), ('f', 1.0)]                                          |\n|('a', 'f')     |[('b', 1.0), ('c', 1.0)]                                          |\n|('b', 'c')     |[('a', 0.3333333333333333), ('f', 0.3333333333333333)]            |\n|('b', 'f')     |[('a', 1.0), ('c', 1.0)]                                          |\n|('c', 'f')     |[('a', 1.0), ('b', 1.0)]                                          |\n|('a', 'b', 'c')|[]                                                                |\n|('a', 'b', 'f')|[]                                                                |\n|('a', 'c', 'f')|[]                                                                |\n|('b', 'c', 'f')|[]                                                                |\n|('d',)         |[('a', 1.0), ('b', 1.0), ('e', 1.0)]                              |\n|('e',)         |[('a', 1.0), ('b', 1.0), ('d', 1.0)]                              |\n|('a', 'd')     |[('b', 1.0), ('e', 1.0)]                                          |\n|('a', 'e')     |[('b', 1.0), ('d', 1.0)]                                          |\n|('b', 'd')     |[('a', 1.0), ('e', 1.0)]                                          |\n|('b', 'e')     |[('a', 1.0), ('d', 1.0)]                                          |\n+---------------+------------------------------------------------------------------+\nonly showing top 20 rows\n\n"}], "source": "def map_to_assoc_rules(rule):\n    key, value = rule    \n    number_key_appearance = value[0][1] #(None, << # >>)\n    confidence_array = []\n    for element_key, ele_appearance in value[1:]:\n        confidence_array.append(tuple((element_key, ele_appearance / number_key_appearance)))\n    yield(key, confidence_array)\n\nassoc_rules = combined_rules.flatMap(map_to_assoc_rules)\n\n# Output as dataframe\nassoc_rules.map(format_tuples).toDF(['patterns', 'association_rules']).show(truncate=False)"}, {"cell_type": "markdown", "metadata": {"id": "BPV5g2hwMa0U"}, "source": "## 3. Instacart dataset (35 points)\n\nAvec votre algorithme MBA pr\u00eat \u00e0 \u00eatre utilis\u00e9, il est maintenant temps de travailler sur l'ensemble de donn\u00e9es r\u00e9el. Pour cette partie du TP, t\u00e9l\u00e9chargez le dataset [instacart](https://drive.google.com/file/d/1pXjqPz1RbL40yCGWnTCbmW_ZXrjlfJi4/view?usp=sharing) et lisez sa [description](https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b) pour comprendre la structure de l'ensemble de donn\u00e9es.\n\nAvant d'appliquer l'algorithme d\u00e9velopp\u00e9 sur l'ensemble de donn\u00e9es instacart, vous devez d'abord filtrer les transactions pour qu'elles soient au m\u00eame format d\u00e9fini par votre algorithme (une transaction par ligne). Pour manipuler les donn\u00e9es, nous pouvons utiliser le bloc de donn\u00e9es de Spark et le module SQL pr\u00e9sent\u00e9 dans la section 1.\n\nLa cellule de code suivante utilise le module Spark SQL pour lire les commandes de ``order_products__train.csv`` et les informations d\u00e9taill\u00e9es de ``orders.csv`` et ``products.csv`` pour construire une dataframe qui contient un liste de tous les produits jamais achet\u00e9s par chaque utilisateur.\n___\nWith your MBA algorithm ready to be used, now it is time to work on the real dataset. For this part of the TP, download the [instacart](https://drive.google.com/file/d/1pXjqPz1RbL40yCGWnTCbmW_ZXrjlfJi4/view?usp=sharing) dataset and read its [description](https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b) to understand how the dataset is structured. \n\nBefore applying the developed algorithm on the instacart dataset, you must first filter the transactions to be in the same format defined by your algorithm (one transaction per row). To manipulate the data, we can use Spark's data frame and the SQL module presented in Section 1.\n\nThe following code cell uses the Spark SQL module to read the orders from the ``order_products__train.csv`` and the detailed information from ``orders.csv`` and ``products.csv`` to construct a data frame that contains a list of all products ever purchased by each user."}, {"cell_type": "code", "execution_count": 54, "metadata": {"id": "6oB1eTkeMa0W"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "order_products__train.csv\n+--------+----------+-----------------+---------+\n|order_id|product_id|add_to_cart_order|reordered|\n+--------+----------+-----------------+---------+\n|       1|     49302|                1|        1|\n|       1|     11109|                2|        1|\n|       1|     10246|                3|        0|\n|       1|     49683|                4|        0|\n|       1|     43633|                5|        1|\n+--------+----------+-----------------+---------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "orders.csv\n+--------+-------+--------+------------+---------+-----------------+----------------------+\n|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|\n+--------+-------+--------+------------+---------+-----------------+----------------------+\n| 2539329|      1|   prior|           1|        2|                8|                  null|\n| 2398795|      1|   prior|           2|        3|                7|                  15.0|\n|  473747|      1|   prior|           3|        3|               12|                  21.0|\n| 2254736|      1|   prior|           4|        4|                7|                  29.0|\n|  431534|      1|   prior|           5|        4|               15|                  28.0|\n+--------+-------+--------+------------+---------+-----------------+----------------------+\nonly showing top 5 rows\n\nproducts.csv\n+----------+--------------------+--------+-------------+\n|product_id|        product_name|aisle_id|department_id|\n+----------+--------------------+--------+-------------+\n|         1|Chocolate Sandwic...|      61|           19|\n|         2|    All-Seasons Salt|     104|           13|\n|         3|Robust Golden Uns...|      94|            7|\n|         4|Smart Ones Classi...|      38|            1|\n|         5|Green Chile Anyti...|       5|           13|\n+----------+--------------------+--------+-------------+\nonly showing top 5 rows\n\ndepartments.csv\n+-------------+----------+\n|department_id|department|\n+-------------+----------+\n|            1|    frozen|\n|            2|     other|\n|            3|    bakery|\n|            4|   produce|\n|            5|   alcohol|\n+-------------+----------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "order_products_prior\n+---+--------+----------+-----------------+---------+\n|_c0|order_id|product_id|add_to_cart_order|reordered|\n+---+--------+----------+-----------------+---------+\n|  0|       2|     33120|                1|        1|\n|  1|       2|     28985|                2|        1|\n|  2|       2|      9327|                3|        0|\n|  3|       2|     45918|                4|        1|\n|  4|       2|     30035|                5|        0|\n+---+--------+----------+-----------------+---------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 247:>                                                        (0 + 2) / 3]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+--------------------------------------------------------------------------------+\n|user_id|                                                                        products|\n+-------+--------------------------------------------------------------------------------+\n|      1|[Zero Calorie Cola, Organic Half & Half, Organic Whole Milk, Aged White Chedd...|\n|      2|[Organic Hearty Split Pea & Uncured Ham Soup, Organic Cashew Carrot Ginger So...|\n|      5|[Organic Baby Arugula, Organic Grape Tomatoes, Tamari Gluten Free Soy Sauce, ...|\n|      7|[Honeycrisp Apple, Organic Dark Brown Sugar, Vanilla Coffee Concentrate, Lact...|\n|      8|[Organic Green Onions, Solid White-No Salt Added Albacore Tuna, Organic Whole...|\n+-------+--------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df_order_prod = spark.read.csv('gs://my_bucket_tp_andi/order_products__train.csv', header=True, sep=',', inferSchema=True)\nprint('order_products__train.csv')\ndf_order_prod.show(5)\n\ndf_orders = spark.read.csv('gs://my_bucket_tp_andi/orders.csv', header=True, sep=',', inferSchema=True)\nprint('orders.csv')\ndf_orders.show(5)\n\ndf_products = spark.read.csv('gs://my_bucket_tp_andi/products.csv', header=True, sep=',', inferSchema=True)\nprint('products.csv')\ndf_products.show(5)\n\ndf_departments = spark.read.csv('gs://my_bucket_tp_andi/departments.csv', header=True, sep=',', inferSchema=True)\nprint('departments.csv')\ndf_departments.show(5)\n\ndf_order_prior = spark.read.csv('gs://my_bucket_tp_andi/order_products__prior.csv', header=True, sep=',', inferSchema=True)\nprint('order_products_prior')\ndf_order_prior.show(5)\n\n\"\"\"\nList of products ever purchased by each user\n\"\"\"\n# USING SQL\ndf_order_prod.createOrReplaceTempView(\"order_prod\") # creates table 'order_prod'\ndf_orders.createOrReplaceTempView(\"orders\") # creates table 'orders'\ndf_products.createOrReplaceTempView(\"products\") # creates table 'products'\ndf_departments.createOrReplaceTempView(\"departments\")\nspark.sql('SELECT o.user_id, COLLECT_LIST(p.product_name) AS products' \n               ' FROM orders o '\n               ' INNER JOIN order_prod op ON op.order_id = o.order_id'\n               ' INNER JOIN products p    ON op.product_id = p.product_id'\n               ' GROUP BY user_id ORDER BY o.user_id').show(5, truncate=80)\n\n\n# USING DATAFRAME OPERATIONS\n# df_orders.join(df_order_prod, df_order_prod.order_id == df_orders.order_id, 'inner')\\\n# .join(df_products, df_products.product_id == df_order_prod.product_id, 'inner')\\\n# .groupBy(df_orders.user_id).agg(f.collect_list(df_products.product_name).alias('products'))\\\n# .orderBy(df_orders.user_id).show(5, truncate=80)"}, {"cell_type": "markdown", "metadata": {"id": "JEqVeqhkMa0a"}, "source": "### 3.1 Perspectives commerciales (20 points) \n\nMaintenant, vous \u00eates le *data scientist*. En ne consid\u00e9rant que les commandes de ``order_products__train.csv``, l'utilisation du module Spark SQL, performant avec SQL ou dataframe, pour r\u00e9pondre aux questions suivantes:\n\n1. Quels sont les 10 produits les plus susceptibles d'\u00eatre command\u00e9 de nouveau? Ne consid\u00e9rez que les produits achet\u00e9s au moins 40 fois pour cette t\u00e2che.\n2. Quels sont les 3 produits les plus achet\u00e9s dans chaque d\u00e9partement?\n4. Quelle est la taille moyenne du panier pour chaque jour de la semaine?\n    - utilisez un barplot pour visualiser vos r\u00e9sultats\n\n**La sortie de ces questions doit contenir le NOM des produits, pas leur ID.**\n___\nNow, you are the data scientist. Considering only the orders of ``order_products__train.csv``, use of Spark SQL module, performing with SQL or data frame, to answer the following questions:\n\n1. What are the top 10 products which have the highest probability of being reordered? Consider only products purchased at least 40 times for this task.\n2. What are the top 3 most purchased products of each department?\n4. What is the average basket size for each day of the week?\n- Hint: use a barplot to visualize your results\n\n**The output of those questions must contain the products' NAME, not their ID.**"}, {"cell_type": "code", "execution_count": 56, "metadata": {"id": "-IxS71fcN_Z0"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 253:============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------------------------+-----------------+------------------+\n|                         product_name|product_occurence|       probability|\n+-------------------------------------+-----------------+------------------+\n|                 2% Lactose Free Milk|               92|0.9347826086956522|\n|                 Organic Low Fat Milk|              368|0.9130434782608695|\n|            100% Florida Orange Juice|               59|0.8983050847457628|\n|              Organic Spelt Tortillas|               81|0.8888888888888888|\n|Original Sparkling Seltzer Water Cans|               45|0.8888888888888888|\n|                               Banana|            18726|0.8841717398269785|\n|                   Petit Suisse Fruit|              120|0.8833333333333333|\n|               Organic Lowfat 1% Milk|              483|0.8819875776397516|\n|  Organic Lactose Free 1% Lowfat Milk|              269|0.8810408921933085|\n|                       1% Lowfat Milk|              461|0.8785249457700651|\n+-------------------------------------+-----------------+------------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\"\"\"\nTop 10 product which have the highest probability of being reordered\n\"\"\"\nspark.sql('SELECT p.product_name, (COUNT(op.product_id)) AS product_occurence,'\n          '(SUM(op.reordered)/COUNT(op.product_id)) AS probability' \n               ' FROM order_prod op '\n               ' INNER JOIN products p ON op.product_id = p.product_id'\n               ' GROUP BY product_name '\n               ' HAVING product_occurence >= 40 '\n               ' ORDER BY probability DESC').show(10, truncate=80)\n"}, {"cell_type": "code", "execution_count": 57, "metadata": {"id": "s6Seg7coOZPs"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 270:==================================>                      (3 + 2) / 5]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------------------------------------------------+----------+-----+---+\n|                                         product_name|department|    o|top|\n+-----------------------------------------------------+----------+-----+---+\n|                                          Blueberries|         1| 2323|  1|\n|                             Organic Broccoli Florets|         1| 1361|  2|\n|                           Organic Whole Strawberries|         1| 1213|  3|\n|                                          Dried Mango|        10|  446|  1|\n|                                  Organic Rolled Oats|        10|  259|  2|\n|                           Organic Black Mission Figs|        10|  125|  3|\n|                                         Cotton Swabs|        11|  258|  2|\n|                                   Lavender Hand Soap|        11|  258|  2|\n|                              Lemon Verbena Hand Soap|        11|  191|  3|\n|                    Boneless Skinless Chicken Breasts|        12| 2088|  1|\n|                                 Ground Turkey Breast|        12|  958|  2|\n|                     Boneless Skinless Chicken Breast|        12|  943|  3|\n|                               Extra Virgin Olive Oil|        13| 2068|  1|\n|                                 Creamy Peanut Butter|        13|  991|  2|\n|                                 Creamy Almond Butter|        13|  850|  3|\n|                                   Honey Nut Cheerios|        14| 1218|  1|\n|                    Organic Old Fashioned Rolled Oats|        14|  747|  2|\n|                                   Raisin Bran Cereal|        14|  600|  3|\n|                                  Organic Black Beans|        15| 1576|  1|\n|                            No Salt Added Black Beans|        15| 1250|  2|\n|                               Organic Garbanzo Beans|        15| 1141|  3|\n|                                   Organic Whole Milk|        16| 4908|  1|\n|                                  Organic Half & Half|        16| 2646|  2|\n|                                          Half & Half|        16| 2424|  3|\n|                           100% Recycled Paper Towels|        17| 1183|  1|\n|                         Sustainably Soft Bath Tissue|        17|  821|  2|\n|                                        Aluminum Foil|        17|  407|  3|\n|     Baby Food Stage 2 Blueberry Pear & Purple Carrot|        18|  310|  1|\n|                Spinach Peas & Pear Stage 2 Baby Food|        18|  268|  2|\n|                Gluten Free SpongeBob Spinach Littles|        18|  259|  3|\n|                 Lightly Salted Baked Snap Pea Crisps|        19|  991|  1|\n|  Pretzel Crisps Original Deli Style Pretzel Crackers|        19|  753|  2|\n|                                  Sea Salt Pita Chips|        19|  707|  3|\n|                                Roasted Almond Butter|         2|  174|  1|\n|              Light CocoWhip! Coconut Whipped Topping|         2|   86|  2|\n|                             Roasted Unsalted Almonds|         2|   62|  3|\n|                                      Original Hummus|        20| 2858|  1|\n|                                 Uncured Genoa Salami|        20| 1788|  2|\n|                              Organic Extra Firm Tofu|        20| 1186|  3|\n|                            Organic Riced Cauliflower|        21|  823|  1|\n|                          Peanut Butter Ice Cream Cup|        21|  261|  2|\n|                                 Organic Celery Bunch|        21|  200|  3|\n|                               100% Whole Wheat Bread|         3| 2298|  1|\n|                   Organic Bread with 21 Whole Grains|         3|  938|  2|\n|                                      Sourdough Bread|         3|  738|  3|\n|                                               Banana|         4|18726|  1|\n|                               Bag of Organic Bananas|         4|15480|  2|\n|                                 Organic Strawberries|         4|10894|  3|\n|                                      Sauvignon Blanc|         5|  295|  1|\n|                                   Cabernet Sauvignon|         5|  237|  2|\n|                                                 Beer|         5|  224|  3|\n|                                       Taco Seasoning|         6|  405|  1|\n|              Organic Sea Salt Roasted Seaweed Snacks|         6|  345|  2|\n|            New Mexico Taco Skillet Sauce For Chicken|         6|  224|  3|\n|                           Sparkling Water Grapefruit|         7| 3359|  1|\n|                                         Spring Water|         7| 2225|  2|\n|                                 Lime Sparkling Water|         7| 1966|  3|\n|Double Duty Advanced Odor Control Clumping Cat Litter|         8|   84|  1|\n|                          24/7 Performance Cat Litter|         8|   76|  2|\n|                            Instant Action Cat Litter|         8|   73|  3|\n|                     Organic Tomato Basil Pasta Sauce|         9|  772|  1|\n|                                       Marinara Sauce|         9|  754|  2|\n|                                          Basil Pesto|         9|  699|  3|\n+-----------------------------------------------------+----------+-----+---+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\"\"\"\nTop 3 most purchased products of each department\n\"\"\"\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndf = spark.sql(\"\"\"SELECT products.product_name, COUNT(order_prod.product_id) AS o, products.department_id AS department\n                  FROM order_prod, products\n                  WHERE products.product_id = order_prod.product_id\n                  GROUP BY products.product_name, products.department_id\n                  ORDER BY products.department_id, o ASC\"\"\")\ndf.createOrReplaceTempView(\"df\")\n\nresult = spark.sql(\"\"\"SELECT df.product_name,df2.department,df.o, COUNT(*) AS top from df join df as df2 on df.department==df2.department  \n                 AND ( df2.o >= df.o) GROUP BY df.product_name,  df2.department, df.o\n                 HAVING COUNT(*) <= 3 ORDER BY df2.department, top ASC\"\"\")\nresult.show(result.count(), truncate=100)"}, {"cell_type": "code", "execution_count": 58, "metadata": {"id": "4MODKAihOdCS"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied: matplotlib in /opt/conda/miniconda3/lib/python3.8/site-packages (3.4.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib) (1.19.5)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib) (2.8.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/miniconda3/lib/python3.8/site-packages (from matplotlib) (9.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"image/png": "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\n", "text/plain": "<Figure size 1000x1000 with 1 Axes>"}, "metadata": {}, "output_type": "display_data"}], "source": "\"\"\"\nAverage basket size for each day of the week\n\"\"\"\n!pip install matplotlib\nimport matplotlib.pyplot as plt\n\ndf = spark.sql(\"\"\"select order_id, count(product_id ) as totorders from order_prod group by order_id\"\"\");\ndf.createOrReplaceTempView(\"df\")\ndf2 = spark.sql(\"\"\"select orders.order_dow, avg(totorders) from df, orders where orders.order_id = df.order_id  group by order_dow order by order_dow\"\"\")\ndays = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\ndf2 = df2.select(\"avg(totorders)\").rdd.flatMap(lambda x: x).collect()\nplt.figure(figsize=(10,10))\nplt.ylabel(\"Day\")\nplt.xlabel(\"Average\")\nplt.title(\"Average basket size for each day of the week\")\nplt.bar(days,df2)\nplt.show()\n\n"}, {"cell_type": "markdown", "metadata": {"id": "PEWqTH1QMa0a"}, "source": "### 3.2 MBA pour le training set / Run MBA for the training set (15 points)\n\nEn utilisant les commandes du ``order_products__train.csv``, cr\u00e9ez un bloc de donn\u00e9es o\u00f9 chaque ligne contient la colonne ``transaction`` avec la liste des produits achet\u00e9s, de mani\u00e8re similaire \u00e0 le toy dataset. Ensuite, ex\u00e9cutez l'algorithme MBA pour cet ensemble de transactions.\n\n- Vous devez signaler le temps pass\u00e9 pour effectuer cette t\u00e2che.\n- La sortie doit contenir le nom des produits.\n___\nUsing the orders from the ``order_products__train.csv``, create a data frame where each row contains the column \u201ctransaction\u201d with the list of purchased products, similarly to the toy dataset. In sequence, run the MBA algorithm for this set of transactions. \n\n- You must report the time spent to perform this task.\n- Output must contain the products' name."}, {"cell_type": "code", "execution_count": 59, "metadata": {"id": "vxZh_f3hMa0b", "scrolled": true}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 283:======================================>                  (4 + 2) / 6]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------+----------------------------------------------------------------------------------------------------+\n|order_id|                                                                                         transaction|\n+--------+----------------------------------------------------------------------------------------------------+\n|       1|Bag of Organic Bananas;Cucumber Kirby;Lightly Smoked Sardines in Olive Oil;Organic 4% Milk Fat Wh...|\n|      36|Cage Free Extra Large Grade AA Eggs;Spring Water;Organic Half & Half;Organic Garnet Sweet Potato ...|\n|      38|Bunched Cilantro;Organic Baby Arugula;Organic Hot House Tomato;Fresh Dill;Flat Parsley, Bunch;Gre...|\n|      96|Roasted Turkey;Organic Cucumber;Organic Raspberries;Organic Whole Strawberries;Organic Grape Toma...|\n|      98|Geranium Liquid Dish Soap;Organic Raspberries;Organic Extra Virgin Oil Olive;100% Organic Unbleac...|\n|     112|Umcka Elderberry Intensive Cold + Flu Berry Flavor;Fresh Cauliflower;I Heart Baby Kale;Hickory Ho...|\n|     170|Classic Movie Theater Popcorn;Brown Rice;BBQ Ranch Chopped Salad;Cherubs Heavenly Salad Tomatoes;...|\n|     218|               Okra;Black Plum;Citrus Mandarins Organic;Organic Yellow Peaches;Natural Artisan Water|\n|     226|\"Magic Tape Refillable Dispenser 3/4\"\" x 850\\\"\"\";Take & Toss 10oz Cups w/ Straws;Wrap Aluminum Fo...|\n|     349|Organic Beef Hot Dogs;Pure Almond Unsweetened Original Almond Milk;Natural Chicken & Sage Breakfa...|\n+--------+----------------------------------------------------------------------------------------------------+\nonly showing top 10 rows\n\nCPU times: user 5.2 ms, sys: 1.87 ms, total: 7.06 ms\nWall time: 3.9 s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\"\"\"\ncreate a query to create and sctruct the transactions\n\"\"\"\nresult = spark.sql('SELECT op.order_id as order_id, concat_ws(\";\", collect_set(p.product_name)) as transaction  '\n                   ' FROM order_prod op '\n                   ' INNER JOIN products p ON p.product_id = op.product_id '\n                   ' GROUP BY op.order_id'\n                   ' ORDER BY op.order_id ASC')\nresult.show(10, truncate=100)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "## CPU Times : user : 2.32ms, sys: 2.27 ms, total : 4.59\n## Wall time : 1.72s"}, {"cell_type": "code", "execution_count": 101, "metadata": {}, "outputs": [], "source": "result_rdd = result.rdd # Create data object from SQL query"}, {"cell_type": "code", "execution_count": 107, "metadata": {"id": "dewN0YUEMa0h", "scrolled": true}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 418:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|patterns                                                                                                |association_rules                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n+--------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|('Organic Pears, Peas and Broccoli Puree Stage 1', 'Organic Pineapple, Apple & Pea Freeze Dried Snacks')|[('Organic Jammy Sammy Snack Size Sandwich Bar Stawberry Jam & Peanut Butter', 1.0), (None, 1.0), ('Grow Well DHA Baby Food', 1.0), ('Stage 1 Apples Sweet Potatoes Pumpkin & Blueberries Organic Pureed Baby Food', 1.0), ('Organic Apples, Carrots and Parsnips Puree', 1.0), ('Spinach Peas & Pear Stage 2 Baby Food', 1.0), ('Double Chocolate Chip Cookies with Dirty Mint Chip Ice Cream', 1.0), ('Whole Wheat Bunnies Baked Snack Crackers', 1.0), ('Organic Amaze Mint Baby Food', 1.0), ('Organic 4 Months Butternut Squash Carrots Apples + Prunes Baby Food', 1.0), ('Blueberry Beet & Brown Rice Cakes', 1.0), (\"Organic D'Anjou Pears\", 1.0), ('Organic Thompson Seedless Raisins', 1.0), ('Organic Garlic Hummus', 1.0), ('Crispy Freeze Dried Bananas', 1.0), ('Bag of Organic Bananas', 1.0), ('Tiny Fruits+Veggies Freeze Dried Snacks Banana Mango & Edamame', 1.0), ('Flaky Biscuits', 1.0), ('Sparkling Water Berry', 1.0), ('Jammy Sammy Apple Cinnamon & Oatmeal Snack Size Sandwich Bar', 1.0), ('Mini Original Babybel Cheese', 1.0), ('Baby Food Stage 2 Pumpkin Banana', 1.0), ('Peter Rabbit Organics Kale Broccoli and Mango Pur\u00e9e', 1.0), ('Zucchini Banana & Amaranth Organic Baby Food', 1.0), ('Organic Lavenberry Puree Level 2', 1.0), ('Bananas, Raspberries & Oats Organic Baby Food', 1.0), ('Super Foods/Organic Apples, Spinach, Peas & Broccoli + Super Chia Snack Pouch', 1.0), ('Baby Food Stage 2 Blueberry Pear & Purple Carrot', 1.0), ('Purity Farms Ghee Clarified Butter', 1.0), ('Peter Rabbit Organic Pea Spinach & Apple Puree Snack', 1.0), ('Just Mangos Organic Baby Food', 1.0), ('Organic Stage 2 Broccoli Pears & Peas Baby Food', 1.0)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n|('Organic Radicchio Castelfranco', 'Organic Raw Sharp Cheddar Cheese')                                  |[(None, 1.0), ('Banana', 1.0), ('Organic Baby Spinach', 1.0), ('Taco Seasoning', 1.0), ('Chocolate Sea Salt', 1.0), ('Comice Pear', 1.0), ('Sparkling Water Berry', 1.0), ('Mild Red Enchilada Sauce', 1.0), ('Organic Small Bunch Celery', 1.0), ('Brioche Slider Buns', 1.0), ('Roasted Turkey Breast', 1.0), ('Organic Large Brown Grade AA Cage Free Eggs', 1.0), ('Yellow Onions', 1.0), ('Organic Russet Potato', 1.0), ('Hass Avocados', 1.0), ('Original Hummus', 1.0), ('Unsalted Butter', 1.0), ('Whipped Cream Cheese', 1.0), ('Organic Milk Reduced Fat, 2% Milkfat', 1.0), ('Organic Sugar Snap Peas', 1.0), ('Gluten Free Sliced Mountain White Bread', 1.0), ('Tomato Ketchup', 1.0)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|('Exquisitely Rich 85% Dark Chocolate', 'Pear, Kiwi, Peas & Spinach Organic Baby Food')                 |[(None, 1.0), ('Stage 1 - Just Prunes', 1.0), ('Organic Whole Grain Oatmeal Cereal Baby Food', 1.0), ('Sweet Potato, White Beans & Cinnamon Stage 2', 1.0), ('Organic Sour Cream', 1.0), ('Organic Red Onion', 1.0), ('Banana & Mango Organic Yogurt & Fruit Snacks\\xa0', 1.0), ('Baby Food Pouch - Kale, Sweet Corn & Quinoa', 1.0), ('Bag of Organic Bananas', 1.0), ('Organic Cucumber', 1.0), ('Arborio White Rice', 1.0), ('Organic Micro Greens Sprouts', 1.0), ('Organic Russian Banana Fingerling Potato', 1.0), ('Baby Food Pouch - Roasted Carrot Spinach & Beans', 1.0), ('Bay Leaves', 1.0), ('Organic Low Sodium Chicken Broth', 1.0), ('Stage 1 Just Peaches Baby Food', 1.0), ('Almonds & Sea Salt in Dark Chocolate', 1.0), ('Hass Avocados', 1.0), ('Organic Vanilla Extract', 1.0), ('Sinfully Sweet Campari Tomatoes', 1.0), ('Yobaby Organic Plain Yogurt', 1.0), ('Supergreens!', 1.0), ('Baby Food Pouch - Butternut Squash, Carrot & Chickpea', 1.0), ('Grated Parmesan', 1.0), ('Baby Food Pouch - Spinach Pumpkin & Chickpea', 1.0), ('Coconut Butter', 1.0), ('Strawberry Lemonade Frozen Pops', 1.0), ('Organic Yellow Onion', 1.0), ('Sharp Cheddar Cheese', 1.0), ('Almond Breeze Almond Coconut Milk', 1.0), ('Large Brown Eggs', 1.0), ('Garlic Hummus', 1.0), ('Coconut Milk Non Dairy Frozen Dessert Chocolate Peanut Butter Swirl', 1.0)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n|('Large Lemon', 'Organic Natural Fresh Goat Cheese')                                                    |[('Mini Seedless Cucumbers', 1.0), ('Banana', 1.0), ('Organic Romaine Lettuce', 1.0), ('Root Beer', 1.0), ('Wild Non-Pareil Capers, Sunkissed in the Mediterranean', 1.0), ('Organic Red Chard', 1.0), ('Klassic 3 Seed Crispbreads', 1.0), ('Red Vine Tomato', 1.0), (None, 4.0), ('Craveables Chicken Club Panini', 1.0), ('Organic Australian Style Vanilla Lowfat Yogurt', 1.0), ('Sweet Potato Yam', 1.0), ('Extra Virgin Olive Oil Rich Taste', 1.0), ('Vanilla Coffee Concentrate', 1.0), ('Chicken Pot Pie', 1.0), ('Hint Of Sea Salt Almond Nut Thins', 1.0), ('Taco Seasoning', 1.0), ('Reduced Fat 2% Chocolate Milk', 1.0), ('Whole Grain Brown Ready Rice', 1.0), ('Nacho Cheese Chips', 1.0), ('Lemon Lime Soda Caffeine Free', 1.0), ('Strawberries', 1.0), ('Beef Broth', 1.0), ('Cashew Cookie', 1.0), ('Lite Raspberry Walnut Vinaigrette Dressing', 1.0), ('Organic Cashew Carrot Ginger Soup', 1.0), ('Tomato Sauce', 1.0), ('Spinach Tagliatelle Nests Pasta', 1.0), ('Organic 1% Milk', 1.0), ('Select Natural Applewood Smoked Turkey Breast', 1.0), ('Unbleached All-Purpose Flour', 1.0), ('Cage Free Brown Eggs-Large, Grade A', 1.0), ('Garlic & Fine Herbs Gournay Cheese', 1.0), ('Lemon Fruit & Nut Food Bar', 1.0), ('Star Wars Macaroni & Cheese', 1.0), ('Black Raspberry Sparkling Water Drink', 1.0), ('2% Reduced Fat DHA Omega-3 Reduced Fat Milk', 1.0), ('Diet Coke', 1.0), ('Red Potatoes', 1.0), ('Organic Spring Mix', 1.0), ('Asparagus', 1.0), ('Green Beans', 1.0), ('Golden Pineapple', 1.0), ('Mini Original Babybel Cheese', 1.0), ('Lime', 1.0), ('Squeeze Tomato Ketchup', 1.0), ('Blueberries', 1.0), ('Four Cheese', 1.0), ('Crisp Apple Sparkling Water', 1.0), ('Small Hass Avocado', 1.0), ('Dairy-Free Chive Cream Cheese', 1.0), ('Sparkling Peach Nectarine Soda', 1.0), ('Organic Gala Apples', 1.0), ('Boneless Skinless Chicken Breast', 1.0), ('Total Greek Strained Yogurt', 1.0), ('Organic Love Crunch Granola Dark Chocolate & Red Berries', 1.0), ('smartwater\u00ae Electrolyte Enhanced Water', 1.0), ('Oven Baked Cheddar & Sour Cream Potato Crisps', 1.0), ('White Miso Soup Mix', 1.0), ('Mint Ice Cream Sandwiches', 1.0), ('Fudge Graham Nutrition Bar', 1.0), ('Chocolate Ice Cream', 1.0), ('Original Baked Whole Grain Wheat Crackers', 1.0), ('Gala Apples', 1.0), ('Green Onions', 1.0), ('Organic Sliced White Mushrooms', 1.0), ('Roasted Garlic Alfredo Pasta Sauce', 1.0), ('Carrots', 1.0), ('Organic Baby Broccoli', 1.0)]|\n|('Fresh Cauliflower', 'Homogenized Milk')                                                               |[(None, 1.0), ('Organic Diced Fire Roasted No Salt Added Tomatoes', 1.0), ('Grape White/Green Seedless', 1.0), ('Organic Portabello Mushroom Pasta Sauce', 1.0), ('Organic Homestyle Waffles', 1.0), ('Organic Bunny Butter Parmesan Pasta', 1.0), (\"Organic Bernie's Farm Macaroni & Cheese\", 1.0), ('Lemon Sparkling Natural Spring Water', 1.0), ('Organic Golden Delicious Apple', 1.0), ('Organic Horseradish Mustard', 1.0), ('Bartlett Pears', 1.0), ('Organic Baby Romaine', 1.0), ('Organic Light in Sodium Lentil Vegetable Soup', 1.0), ('Traditional Kettle Style Tofu', 1.0), ('Small Hass Avocado', 1.0), ('Mini Seedless Cucumbers', 1.0), ('Organic Plain Greek Whole Milk Yogurt', 1.0), ('Raspberries', 1.0), ('Organic Ketchup', 1.0)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n+--------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\nCPU times: user 10.4 ms, sys: 5.58 ms, total: 16 ms\nWall time: 2min 16s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\"\"\"\nTODO: run the MBA algorithm and show the first 5 association rules\n\"\"\"\nresult_rdd = result_rdd.flatMap(map_to_patterns)\nresult_rdd.map(format_tuples).toDF(['patterns', 'occurrences'])\n\nresult_rdd = result_rdd.reduceByKey(reduce_patterns)\nresult_rdd.map(format_tuples).toDF(['patterns', 'combined_occurrences'])\n\nresult_rdd = result_rdd.flatMap(map_to_subpatterns)\nresult_rdd = result_rdd.map(format_tuples).toDF(['subpatterns', 'rules'])\n\nresult_rdd = result_rdd.groupByKey().mapValues(list)\nresult_rdd.map(format_tuples).toDF(['subpatterns', 'combined_rules'])\n\n\nresult_rdd = result_rdd.flatMap(map_to_assoc_rules)\nresult_rdd.map(format_tuples).toDF(['patterns', 'association_rules']).show(5,truncate=False)\n\n\n"}, {"cell_type": "code", "execution_count": 106, "metadata": {}, "outputs": [], "source": "# CPU times: user 84ms, sys: 96.9ms, total : 181ms\n# Wall time: 18min 49s"}, {"cell_type": "markdown", "metadata": {"id": "5DkNPEtGMa0l"}, "source": "## 4. MBA pour le dataset complet / MBA for the full dataset (20 points)\n\nComme vous l'avez probablement remarqu\u00e9, m\u00eame pour un ensemble de donn\u00e9es moins volumineux (le training dataset ne contient que 131 000 commandes), l'algorithme MBA est co\u00fbteux en calcul. Pour cette raison, cette fois, nous allons r\u00e9p\u00e9ter le processus, mais en utilisant maintenant Google Cloud Platform (GCP) pour cr\u00e9er un grand cluster. Toutes les instructions pour cr\u00e9er un cluster avec spark et comment soumettre un travail seront expliqu\u00e9es dans le laboratoire. Dans tous les cas, vous devez lire les instructions donn\u00e9es dans le ``Instruction_GCP.pdf``.\n\nCette fois, nous travaillerons avec le fichier ``order_products__prior.csv``, qui contient plus de 3M commandes.\n\n**PRODUCTION ATTENDUE**\n\nApr\u00e8s avoir ex\u00e9cut\u00e9 le MBA pour la plus grande collection de commandes, s\u00e9lectionnez au hasard UN produit achet\u00e9 dans ``order_products__prior`` et affichez les r\u00e8gles d'association (nom du produit et valeur d'association) de ce produit, c'est-\u00e0-dire lorsque le produit est seul dans le panier. La sortie doit \u00eatre format\u00e9e dans un tableau, o\u00f9 chaque ligne contenant les informations d'un produit associ\u00e9. \n\n- Affichez l'ID et le nom du produit s\u00e9lectionn\u00e9 au hasard.\n- Signaler le temps d'ex\u00e9cution.\n\n**Remarque importante\u00a0: joignez des captures d'\u00e9cran de votre sortie et de votre configuration de cluster.** \n___\nAs you probably noticed, even for a not so large data set (the training file has only 131K orders), the MBA algorithm is computationally expensive. For that reason, this time, we will repeat the process, but now using the Google Cloud Platform (GCP) to create a large computer cluster. All the instructions for creating a computing cluster with spark and how to submit a job will be explained in both sessions of the laboratory. In any case, you should read the instructions given in the ``Instruction_GCP.pdf``.\n\nThis time, we will work with the ``order_products__prior.csv`` file, which contains more than 3M orders.\n\n**EXPECTED OUTPUT**\n\nAfter you ran the MBA for the larger collection of orders, randomly select ONE product purchased in ``order_products__prior`` and print the association rules (product name and association value) of this product, i.e., when the product is alone in the basket. The output should be formatted in a table, where each row containing the information of one associated product.\n\n- Print both ID and Name of the random selected product.\n- Report the execution time.\n\n**Important note: Attach screenshots from your output and configuration of your cluster.** "}, {"cell_type": "code", "execution_count": 32, "metadata": {"id": "X1cVWxraMa0l", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 114:==================================>                      (3 + 2) / 5]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------+--------------------+\n|order_id|         transaction|\n+--------+--------------------+\n|       2|Garlic Powder;Coc...|\n|       3|Air Chilled Organ...|\n|       4|Tiny Twists Pretz...|\n|       5|Artichokes;Aprico...|\n|       6|Clean Day Lavende...|\n|       7|Orange Juice;Pine...|\n|       8|Original Hawaiian...|\n|       9|French Baguettes,...|\n|      10|Organic Cilantro;...|\n|      11|Mango Pineapple S...|\n|      12|All Natural Bonel...|\n|      13|Handmade Vodka Fr...|\n|      14|Total Greek Strai...|\n|      15|Organic Extra Vir...|\n|      16|Sea Salt Made Wit...|\n|      18|Globe Eggplant;Ba...|\n|      19|Organic Whole Whi...|\n|      20|Nilla Wafers;Red ...|\n|      21|Organic Firm Tofu...|\n|      22|Cream Cheese;Pres...|\n+--------+--------------------+\nonly showing top 20 rows\n\nCPU times: user 16.2 ms, sys: 4.09 ms, total: 20.3 ms\nWall time: 22.7 s\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "%%time\n\"\"\"\nTODO: create a query to create and sctruct the transactions from the order_products__prior.csv file\n\"\"\"\ndf_order_prior = spark.read.csv('gs://my_bucket_tp_andi/order_products__prior.csv', header=True, sep=',', inferSchema=True)\ndf_order_prior.createOrReplaceTempView(\"df_order_prior\") # create table\n\nfull_mba = spark.sql('SELECT op.order_id as order_id, concat_ws(\";\", collect_set(p.product_name)) as transaction  '\n                   ' FROM df_order_prior op '\n                   ' INNER JOIN products p ON p.product_id = op.product_id '\n                   ' GROUP BY op.order_id'\n                   ' ORDER BY op.order_id ASC')\n\nfull_mba.show()\n"}, {"cell_type": "code", "execution_count": 33, "metadata": {"id": "MVBQ12b2Ma0o"}, "outputs": [{"ename": "NameError", "evalue": "name 'transactions' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "File \u001b[0;32m<timed exec>:4\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'transactions' is not defined"]}], "source": "%%time\n\"\"\"\nTODO: run the MBA algorithm and print the requested output\n\"\"\"\n\nfull_mba = full_mba.flatMap(map_to_patterns)\nfull_mba.map(format_tuples).toDF(['patterns', 'occurrences'])\n\nfull_mba = full_mba.reduceByKey(reduce_patterns)\nfull_mba.map(format_tuples).toDF(['patterns', 'combined_occurrences'])\n\nfull_mba = full_mba.flatMap(map_to_subpatterns)\nfull_mba = full_mba.map(format_tuples).toDF(['subpatterns', 'rules'])\n\nfull_mba = full_mba.groupByKey().mapValues(list)\nfull_mba.map(format_tuples).toDF(['subpatterns', 'combined_rules'])\n\n\nfull_mba = full_mba.flatMap(map_to_assoc_rules)\nfull_mba.map(format_tuples).toDF(['patterns', 'association_rules']).show(5,truncate=False)\n\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"colab": {"collapsed_sections": [], "provenance": []}, "kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 4}